{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "1. Import modules\n",
    "2. Explore datasets: feature data, training data\n",
    "3. Data cleaning:\n",
    "    1. Text cleaning\n",
    "    2. Text normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from text_utils import text_cleaner, text_merger\n",
    "from image_utils import image_data_extractor, detect_bounding_box_parallel, crop_pad_and_resize_image_parallel, find_duplicates_parallel, create_duplicates_dataframe\n",
    "\n",
    "X_test = pd.read_csv(\"X_test.csv\", index_col=0)\n",
    "X_train = pd.read_csv(\"X_train.csv\", index_col=0)\n",
    "y_train = pd.read_csv(\"y_train.csv\", index_col=0)\n",
    "\n",
    "# Create DataFrame for text content like 'designation' and 'decription'\n",
    "df_text = pd.merge(X_train, y_train, left_index=True, right_index=True)\n",
    "\n",
    "# Create DataFrame for images\n",
    "#df_image = df_text.drop(columns=[\"designation\", \"description\"])\n",
    "#df_image.set_index(keys=\"productid\", inplace=True)\n",
    "\n",
    "#df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display basic **information** about the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_text.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the size of the original dataset for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get size of DataFrame\n",
    "cells = df_text.size\n",
    "\n",
    "# Get shape of DataFrame in order to get number of rows (products) and columns (attributes)\n",
    "df_text.shape\n",
    "\n",
    "rows = df_text.shape[0]\n",
    "cols = df_text.shape[1]\n",
    "\n",
    "print(f'The original dataset contains a total of {cells:,} cells.', end='\\n\\n')\n",
    "print(f'The data are distributed over {rows:,} products with {cols} attributes:')\n",
    "\n",
    "# Get names of columns for better understanding of attributes\n",
    "column_names = df_text.columns\n",
    "\n",
    "for nr, cn in enumerate(column_names, start=1): # nr as in \"number\", cn as in \"column name\"\n",
    "    print(f'\\t{nr}. {cn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Are there any missing values (NaN)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The original data set has missing descriptions:')\n",
    "\n",
    "df_text.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How many missing values are we looking at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_nan = df_text['description'].isna()\n",
    "description_nan_amt = description_nan.sum()\n",
    "\n",
    "print(f'The training data has {description_nan_amt:,} missing values in the column \\'description\\'.')\n",
    "\n",
    "df_text.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate values\n",
    "Step 2 // Preprocessing: Duplicate items [[Issue #16]](https://github.com/PeterStieg/feb25_bds_classification-of-rakuten-e-commerce-products/issues/16)\n",
    "- Amount of duplicate values per column (attribute)\n",
    "- Most frequent product titles (designation)\n",
    "- Most frequent product description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Are there any duplicate values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_values = {}\n",
    "\n",
    "for cn in column_names:\n",
    "   cn_duplicates = df_text[cn].duplicated().sum()\n",
    "   \n",
    "   if cn_duplicates:\n",
    "      pct = cn_duplicates / rows\n",
    "      print(f'The column \\033[1m\\'{cn}\\'\\033[0m has {cn_duplicates:,} duplicate values: {pct:.2%}')\n",
    "      \n",
    "      # Add data to dictionary for later comparison\n",
    "      duplicate_values[cn] = [int(cn_duplicates), round(pct, 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What are the most common duplicate values for product titles (designation)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designation_value_counts = df_text['designation'].value_counts().sort_values(ascending=False)\n",
    "designation_value_counts_top5 = designation_value_counts.iloc[:5]\n",
    "print(designation_value_counts_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What are the most common duplicate values for product descriptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_value_counts = df_text['description'].value_counts().sort_values(ascending=False)\n",
    "description_value_counts_top5 = description_value_counts.iloc[:5]\n",
    "print(description_value_counts_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How many products with missing descriptions have duplicated designations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows of DataFrame with missing descriptions\n",
    "df_descr_nan = df_text[description_nan] # filter defined in 'Exploration of text data'\n",
    "\n",
    "# Get number of rows with duplicate titles (designation)\n",
    "missDescription_duplTitle_amt = df_descr_nan['designation'].duplicated().sum()\n",
    "\n",
    "print(f'Only {missDescription_duplTitle_amt:,} products with a missing description have a duplicate title (designation).', end='\\n\\n')\n",
    "print(f'Compared to a total of {description_nan_amt:,} products with a missing description, this is only {missDescription_duplTitle_amt / description_nan_amt:.2%} of the total.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Does the number of duplicate titles and descriptions increase after **cleaning the string variables?**\n",
    "\n",
    "**Proprecessing steps** with function *text_cleaner()* from text_utils.py, which\n",
    "1. Removes:\n",
    "    1. Leading and trailing spaces \n",
    "    2. HTML tags, e.g. \\<br>, \\<br />, \\<b>\n",
    "\n",
    "2. Replaces:\n",
    "    1. HTML entities with their corresponding characters, e.g. &eacute; → è, &auml; → ä, &ntilde; → ñ \n",
    "    2. Control characters with empty strings, e.g. Ã, Â©, �\n",
    "    3. Multiple spaces with a single space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame with cleaned text columns\n",
    "\n",
    "#df_text_clean = text_cleaner(df_text) # Duration 16apr2025: 5min 39s\n",
    "#df_text_clean.to_csv('df_text_clean.csv', index=False)\n",
    "#df_text_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "1. What do the cleaned strings look like?\n",
    "2. How many characters did we save by cleaning strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_clean = pd.read_csv('df_text_clean.csv')\n",
    "df_text_copy = df_text_clean.copy()\n",
    "\n",
    "df_text_len = df_text_copy[[\"designation\", \"designation_cleaned\", \"designation_len\", \"designation_cleaned_len\", \"designation_saved_len\", \"description\", \"description_cleaned\", \"description_len\", \"description_cleaned_len\", \"description_saved_len\"]]\n",
    "\n",
    "designation_len = df_text_len['designation_len'].sum()\n",
    "description_len = df_text_len['description_len'].sum()\n",
    "designation_saved_len = df_text_len['designation_saved_len'].sum()\n",
    "\n",
    "designation_cleaned_len = df_text_len['designation_cleaned_len'].sum()\n",
    "description_cleaned_len = df_text_len['description_cleaned_len'].sum()\n",
    "description_saved_len = df_text_len['description_saved_len'].sum()\n",
    "\n",
    "pct_saved = (designation_saved_len + description_saved_len) / (designation_len + description_len) * 100\n",
    "\n",
    "print(f\"\\033[1mDesignation\\033[0m:\")\n",
    "print(f\"\\tTotal length of designation: {designation_len:,}\")\n",
    "print(f\"\\tTotal length of cleaned designation: {designation_cleaned_len:,}\")\n",
    "print(f\"\\tAmount of saved chars in designation: {designation_saved_len:,}\", end=\"\\n\\n\")\n",
    "\n",
    "print(f\"\\033[1mDescription\\033[0m:\")\n",
    "print(f\"\\tTotal length of description: {description_len:,}\")\n",
    "print(f\"\\tTotal length of cleaned description: {description_cleaned_len:,}\")\n",
    "print(f\"\\tAmount of saved chars in description: {description_saved_len:,}\", end=\"\\n\\n\")\n",
    "\n",
    "print(f\"\\033[1mSummary\\033[0m:\")\n",
    "print(f\"\\tTotal amount of saved chars: {designation_saved_len + description_saved_len:,} ({pct_saved:.2f}%)\")\n",
    "\n",
    "df_text_len_sorted = df_text_len.sort_values(by = \"description_saved_len\", ascending=False)\n",
    "\n",
    "df_text_len_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison** of number of duplicates in the orig. and cleaned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = ['designation_cleaned', 'description_cleaned']\n",
    "\n",
    "for cn_clean in text_cols:\n",
    "  cn_duplicates = df_text_clean[cn_clean].duplicated().sum()\n",
    "  pct = cn_duplicates / rows\n",
    "\n",
    "  # Get the previous value from the dictionary\n",
    "  \n",
    "  cn = re.sub('_cleaned', '', cn_clean)\n",
    "  pct_incr = pct - duplicate_values[cn][1]\n",
    "\n",
    "  print(f'The cleaned column \\033[1m\\'{cn_clean}\\'\\033[0m has...')\n",
    "  print(f'\\t{cn_duplicates:,} duplicates compared to {duplicate_values[cn][0]:,} (+{cn_duplicates - duplicate_values[cn][0]:,})')\n",
    "  print(f'\\tAn increase of {pct_incr:.2%} from {duplicate_values[cn][1]:.2%} to {pct:.2%}', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Does the number of identical original string variables differ from cleaned string variables?\n",
    "\n",
    "**Proprecessing steps** with function *text_merger()* from text_utils.py:\n",
    "1. Compare original string variables and set flags\n",
    "2. Compare cleaned string variables and set flags\n",
    "3. Merge cleaned string variables – if applicable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_text_merge = text_merger(df_text_clean) # Duration 11apr2025: 23s\n",
    "\n",
    "#df_text_merge.to_csv('df_text_merge.csv', index=False)\n",
    "#df_text_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing // Load DataFrame with image data\n",
    "`Note:` The repository contains an updated and preprocessed version of df_image.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image = pd.read_csv(\"df_image.csv\", index_col=\"productid\")\n",
    "\n",
    "#df_image.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing // Images**\n",
    "\n",
    "`NOTE:` Running the following cell to extract data from all image files and save it to df_image.csv is **only necessary after** an update of the module image_utils.py. Otherwise you can proceed with the import in the next code cell of you interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_image = image_data_extractor(df_image)         # Command takes a while to run: ~ 1 hour\n",
    "#df_image.to_csv('df_image.csv', index=False)\n",
    "#df_image.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import image data**\n",
    "1. File information, e.g.\n",
    "    1. productid\n",
    "    2. imageid\n",
    "2. Size information\n",
    "    1. width, height, ...\n",
    "    2. aspect_ratio\n",
    "3. EXIF and meta data\n",
    "    1. meta_jfif, ... meta_progressive, ...\n",
    "    2. mean_r, mean_g, mean_b, mean_brightness, ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How many aspect ratios are in the DataFrame?\n",
    "\n",
    "**Answer:** All product images have an aspect ratio of 1:1 with a resolution of 500 × 500 px\n",
    "\n",
    "Relates to [Issue #45 Step 2 // Preprocessing: Image Processing](https://github.com/PeterStieg/feb25_bds_classification-of-rakuten-e-commerce-products/issues/45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt_img_ar as in \"Pivot Table for Images' Aspect Ratio\"\n",
    "pt_img_ar = pd.pivot_table(df_image[['aspect_ratio', 'width', 'height']],\n",
    "                           index='aspect_ratio',\n",
    "                           aggfunc={'aspect_ratio': 'count', 'height': 'mean', 'width': 'mean'})\n",
    "\n",
    "pt_img_ar = pt_img_ar.rename(columns={'aspect_ratio': 'count'})\n",
    "\n",
    "pt_img_ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing // Images: Detect bounding boxes\n",
    "\n",
    "Relates to Issue [Issue #62 Step 2 // Preprocessing: Object localization via bounding boxes in images](https://github.com/PeterStieg/feb25_bds_classification-of-rakuten-e-commerce-products/issues/62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_image = detect_bounding_box_parallel(df_image) # Duration 22apr2025: 6 min\n",
    "\n",
    "#df_image.to_csv(\"df_image.csv\", index=True)\n",
    "\n",
    "#df_image.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing // Images: Crop and resize to target size\n",
    "\n",
    "Relates to Issue [Issue #63 Step 2 // Preprocessing: Crop and resize image](https://github.com/PeterStieg/feb25_bds_classification-of-rakuten-e-commerce-products/issues/63)\n",
    "1. Crop and resize images contained in a DataFrame according to bounding box dimensions\n",
    "2. Add columns 'downscaled', 'upscaled' and 'exclude' to DataFrame df_image(.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image = pd.read_csv(\"df_image.csv\", index_col=\"productid\")\n",
    "df_image = crop_pad_and_resize_image_parallel(df_image) # Duration 22apr2025: 6min 34s\n",
    "#df_image.to_csv(\"df_image.csv\")\n",
    "#df_image.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing // Images: Find duplicates with perceptual hashing\n",
    "\n",
    "Relates to Issue [Issue #67 Step 2 // Preprocessing: Find duplicates with perceptual hashing](https://github.com/PeterStieg/feb25_bds_classification-of-rakuten-e-commerce-products/issues/67)\n",
    "1. Compute perceptual hash\n",
    "2. Add columns 'phash' to DataFrame df_image(.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_image = pd.read_csv(\"df_image.csv\", index_col=\"productid\")\n",
    "#df_image = hash_parallel(df_image) # Duration 22apr2025: 5min 14s\n",
    "#df_image.to_csv(\"df_image.csv\")\n",
    "#df_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 84,916 images in 141 chunks using 14 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding duplicate hashes: 100%|██████████| 141/141 [42:25<00:00, 18.06s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29538 unique duplicate pairs with threshold 0\n",
      "Marked 11517 images as duplicates in the DataFrame\n"
     ]
    }
   ],
   "source": [
    "#df_image = pd.read_csv(\"df_image.csv\", index_col=\"productid\")\n",
    "\n",
    "#df_image, unique_duplicates = find_duplicates_parallel(df_image, threshold=0) # Duration 23apr2025: 42min\n",
    "#df_image.to_csv(f\"df_image.csv\")\n",
    "\n",
    "# Create a DataFrame from the duplicate pairs\n",
    "#df_image_duplicates = create_duplicates_dataframe(unique_duplicates)\n",
    "#df_image_duplicates.to_csv(f\"df_image_duplicates.csv\", index=False)\n",
    "#df_image_duplicates.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of target data (product type code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What does the target data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display basic **information** about the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Are there any missing values (NaN)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The attribute \\033[1m'product type code'\\033[0m has no missing data:\")\n",
    "\n",
    "y_train.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How many different product type codes are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prdtypecode_list = sorted(set(y_train['prdtypecode']))\n",
    "prdtypecode_len = len(prdtypecode_list)\n",
    "\n",
    "print(f\"List containing all \\033[1m{prdtypecode_len} product type codes\\033[0m:\")\n",
    "print(prdtypecode_list, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assigning Product Type Codes to Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary for French category names:\n",
    "# Product type code -> Product Category, French\n",
    "prdtypecode_dict_FR = {   \n",
    "    10: 'Livres > ??More than 1 Sub-Category??',\n",
    "    2280: 'Livres > Revue',\n",
    "    2705: 'Livres > eBooks',\n",
    "    2522: 'Livres > Fournitures Papeterie',\n",
    "    2403: 'Livres > Lots de Livres et de Revues',\n",
    "\n",
    "    50: 'Jeux vidéo & Consoles > Accessoires Jeux Vidéo',\n",
    "    1140: 'Jeux vidéo & Consoles > Figurines',\n",
    "    1180: 'Jeux vidéo & Consoles > Jeux de rôle et jeux de figurines',\n",
    "    2462: 'Jeux vidéo & Consoles > Lots de consoles et jeux vidéo',\n",
    "    1160: 'Jeux vidéo & Consoles Cartes de jeux',\n",
    "    40: 'Jeux vidéo & Consoles > Jeux Vidéo',\n",
    "    60: 'Jeux vidéo & Consoles > Consoles',\n",
    "    2905: 'Jeux vidéo & Consoles > Jeux Vidéo > Jeux vidéo PC', #3. Ebene! Unterkategorie von 60\n",
    "    \n",
    "    1280: 'Jouets > Enfant Jouets',\n",
    "    1300: 'Jouets & Enfant > Modélisme',\n",
    "    1320: 'Jouets & Enfant > Puériculture',\n",
    "    1302: 'Jouets & Enfant Jeux de plein air',\n",
    "    1301: 'Jouets & Enfant > Jeux de café',\n",
    "    1281: 'Jouets & Enfant > Jeux de société ',\n",
    "    \n",
    "    2582: 'Jardin & Piscine > Mobilier de jardin',\n",
    "    2583: 'Jardin & Piscine > Entretien piscine & spa',\n",
    "    2585: 'Jardin & Piscine > Outillage de jardin',\n",
    "\n",
    "    1560: 'Maison > Mobilier ',\n",
    "    1920: '??Maison > 1640 Linge de Maison ??',#nochmal checken\n",
    "    2060: '??Maison > decoration??', #nochmal checken\n",
    "\n",
    "    1940: 'Vins et Gastronomie > Petit déjeuner',\n",
    "\n",
    "    2220: 'Animalerie > Accessoires et nourriture pour chien'\n",
    "    }\n",
    "\n",
    "                          \n",
    "# Map the French dictionary to prdtypecode column\n",
    "df_text['prod_cat_fr'] = df_text['prdtypecode'].map(prdtypecode_dict_FR)                          \n",
    "                                            \n",
    "\n",
    "# Define a dictionary for English category names:\n",
    "# Product type code -> Product Category, English\n",
    "# Peter 31mar2025: We could simplify the code by using a single dictionary for both French and English categories.\n",
    "prdtypecode_dict_EN = {\n",
    "    10: 'Books > ??More than 1 Sub-Category??',\n",
    "    2280: 'Books > Magazine',\n",
    "    2705: 'Books > eBooks',\n",
    "    2522: 'Books > Stationery Supplies',\n",
    "    2403: 'Books > Batches of Books and Magazines',\n",
    "\n",
    "    50: 'Video Games & Consoles > Video Game Accessories',\n",
    "    1140: 'Video Games & Consoles > Figures',\n",
    "    1180: 'Video Games & Consoles > Role-playing games and miniature games',\n",
    "    2462: 'Video Games & Consoles > Batches of consoles and video games',\n",
    "    1160: 'Video Games & Consoles Game cards',\n",
    "    40: 'Video Games & Consoles > Video Games',\n",
    "    60: 'Video Games & Consoles > Consoles',\n",
    "    2905: 'Video Games & Consoles > Video Games > PC video games', #3. Ebene! Unterkategorie von 60\n",
    "    \n",
    "    1280: 'Toys & Children > Toys',\n",
    "    1300: 'Toys & Children > Model making',\n",
    "    1320: 'Toys & Children > Childcare',\n",
    "    1302: 'Toys & Children > Outdoor games',\n",
    "    1301: 'Toys & Children > Cafe games',\n",
    "    1281: 'Toys & Children > Board games',\n",
    "    \n",
    "    2582: 'Garden & Pool > Garden furniture',\n",
    "    2583: 'Garden & Pool > Pool & spa maintenance',\n",
    "    2585: 'Garden & Pool > Garden tools',\n",
    "\n",
    "    1560: 'Home > Furniture',\n",
    "    1920: '??Home > 1640 Household Linens??',#nochmal checken\n",
    "    2060: '??Home > decoration??', #nochmal checken\n",
    "\n",
    "    1940: 'Wines and Gastronomy > Breakfast',\n",
    "\n",
    "    2220: 'Pet Store > Dog Accessories and Food'\n",
    "    }\n",
    "\n",
    "# Map the English dictionary to prdtypecode column\n",
    "df_text['prod_cat_en'] = df_text['prdtypecode'].map(prdtypecode_dict_EN)                          \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Category / Subcategory?\n",
    "Issues:\n",
    "\n",
    "1. Category 10 seems to belong to more than one subcategory of books, yet it is not the parent category of the other subcategories. (100)\n",
    "2. Category 60 seems to be the parent category of 2905.\n",
    "3. I can not confirm Categories 1920 & 2060. I could not find them in the html/css code of the website.\n",
    "\n",
    "Suggestions:\n",
    "1. ?\n",
    "2. Change Category 2950 to 60 for consistency. Check for duplicates in category 60.\n",
    "3. ?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Display DataFrame 'df_text' to verify\n",
    "display(df_text.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assigning Parent Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary for parent categories in French\n",
    "parent_category_dict_fr = {\n",
    "    10: 'Livres',\n",
    "    2280: 'Livres',\n",
    "    2705: 'Livres',\n",
    "    2522: 'Livres',\n",
    "    2403: 'Livres',\n",
    "    50: 'Jeux vidéo et consoles',\n",
    "    1140: 'Jeux vidéo et consoles',\n",
    "    1180: 'Jeux vidéo et consoles',\n",
    "    2462: 'Jeux vidéo et consoles',\n",
    "    1160: 'Jeux vidéo et consoles',\n",
    "    40: 'Jeux vidéo et consoles',\n",
    "    60: 'Jeux vidéo et consoles',\n",
    "    2905: 'Jeux vidéo et consoles',  # Parent category of 2905 is 60\n",
    "    1280: 'Jouets et enfants',\n",
    "    1300: 'Jouets et enfants',\n",
    "    1320: 'Jouets et enfants',\n",
    "    1302: 'Jouets et enfants',\n",
    "    1301: 'Jouets et enfants',\n",
    "    1281: 'Jouets et enfants',\n",
    "    2582: 'Jardin et piscine',\n",
    "    2583: 'Jardin et piscine',\n",
    "    2585: 'Jardin et piscine',\n",
    "    1560: 'Maison',\n",
    "    1920: 'Maison',\n",
    "    2060: 'Maison',\n",
    "    1940: 'Vins et gastronomie',\n",
    "    2220: 'Animalerie'\n",
    "    }\n",
    "\n",
    "# Map the parent category to a new column using the French dictionary\n",
    "df_text['parent_category_fr'] = df_text['prdtypecode'].map(parent_category_dict_fr)\n",
    "\n",
    "\n",
    "# Define a dictionary for English parent categories\n",
    "# Peter 31mar2025: We could simplify the code by using a single dictionary for both French and English categories.\n",
    "parent_category_dict_en = {\n",
    "    10: 'Books',\n",
    "    2280: 'Books',\n",
    "    2705: 'Books',\n",
    "    2522: 'Books',\n",
    "    2403: 'Books',\n",
    "    50: 'Video Games & Consoles',\n",
    "    1140: 'Video Games & Consoles',\n",
    "    1180: 'Video Games & Consoles',\n",
    "    2462: 'Video Games & Consoles',\n",
    "    1160: 'Video Games & Consoles',\n",
    "    40: 'Video Games & Consoles',\n",
    "    60: 'Video Games & Consoles',\n",
    "    2905: 'Video Games & Consoles',  # Parent category of 2905 is 60\n",
    "    1280: 'Toys & Children',\n",
    "    1300: 'Toys & Children',\n",
    "    1320: 'Toys & Children',\n",
    "    1302: 'Toys & Children',\n",
    "    1301: 'Toys & Children',\n",
    "    1281: 'Toys & Children',\n",
    "    2582: 'Garden & Pool',\n",
    "    2583: 'Garden & Pool',\n",
    "    2585: 'Garden & Pool',\n",
    "    1560: 'Home',\n",
    "    1920: 'Home',\n",
    "    2060: 'Home',\n",
    "    1940: 'Wines and Gastronomy',\n",
    "    2220: 'Pet Store'\n",
    "    }\n",
    "\n",
    "\n",
    "# Map the parent category to a new column using the English dictionary\n",
    "df_text['parent_category_en'] = df_text['prdtypecode'].map(parent_category_dict_en)\n",
    "\n",
    "\n",
    "# Display DataFrame 'df_text' to verify\n",
    "display(df_text.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMPORTANT NOTES:\n",
    "\n",
    "Text normalization has been put into backlog of our project. Since I have already started working on this process, I did not want to loose progress. \n",
    "All the following steps are just a first sketch of the process.\n",
    "\n",
    "\n",
    "- In the described process: Stemming or lemmatization is not included because contextual embeddings (CamemBERT) already handle word variations and synonyms effectively.\n",
    "- synonym mapping, regular expressions, and tokenization are largely redundant when using contextual embeddings like CamemBERT.\n",
    "- Stopword removal is optional when using contextual embeddings like CamemBERT, as they can handle common words effectively.\n",
    "\n",
    "\n",
    "If we want to apply the following we must save it for the test data, \n",
    "to be processed in the same way as the training data. Can this be handled in the pipeline?\n",
    "\"\"\"\n",
    "\n",
    "#ALL CODE IN TRIPPLE QUOTES TO NOT EXECUTE IT\n",
    "\n",
    "\"\"\"\n",
    "# 1. Lowercasing and Remove Accents\n",
    "#Normalize the text by lowercasing and removing accents. This step ensures consistency.\n",
    "\n",
    "import unicodedata \n",
    "# Peter 31mar2025: I could/would use this module in the function text_cleaner() during text cleaning\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove accents\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "    return text\n",
    "\n",
    "# Apply normalization to both columns\n",
    "df_text['designation'] = df_text['designation'].apply(normalize_text)\n",
    "df_text['description'] = df_text['description'].apply(normalize_text)\n",
    "\n",
    "# 2. Generating Contextual Embeddings\n",
    "#Using CamemBERT to generate embeddings for each row in the title and description columns. \n",
    "#This step captures the semantic meaning of the text.\n",
    "\n",
    "from transformers import CamembertTokenizer, CamembertModel \n",
    "# Peter 31mar2025: I would move all imports to the setup section of the notebook\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "model = CamembertModel.from_pretrained(\"camembert-base\")\n",
    "\n",
    "import torch\n",
    "\n",
    "def get_embedding(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    # Pass the input through the model\n",
    "    outputs = model(**inputs)\n",
    "    # Extract the embeddings (mean of the last hidden state)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "# Generate embeddings for titles and descriptions\n",
    "df_text['designation_embedding'] = df_text['designation'].apply(get_embedding)\n",
    "df_text['description_embedding'] = df_text['description'].apply(get_embedding)\n",
    "\n",
    "# 3. Automatically Cluster Similar Rows\n",
    "#Instead of manually defining synonyms or rules, using unsupervised clustering to group similar rows based on their embeddings.\n",
    "import numpy as np\n",
    "\n",
    "# Combining title and description embeddings\n",
    "# Combining the designation_embedding and description_embedding into a single vector for each row.\n",
    "df_text['combined_embedding'] = df_text.apply(\n",
    "    lambda row: np.mean([row['designation_embedding'], row['description_embedding']], axis=0),\n",
    "    axis=1\n",
    ")\n",
    "# Cluster Rows\n",
    "#Using K-Means clustering to group similar rows based on their combined embeddings.\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Stack all embeddings into a matrix\n",
    "embedding_matrix = np.vstack(df_text['combined_embedding'])\n",
    "\n",
    "# Cluster embeddings into groups\n",
    "num_clusters = 5  # Adjust based on your dataset\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "df_text['cluster'] = kmeans.fit_predict(embedding_matrix)\n",
    "\n",
    "# 4. Replace Text with Cluster Representatives\n",
    "# Automatically replace the text in each cluster with a representative phrase \n",
    "# (e.g., the most frequent phrase in the cluster).\n",
    "\n",
    "# Find Cluster Representatives\n",
    "# Find the most common title or description in each cluster.\n",
    "\n",
    "# Find the representative title for each cluster\n",
    "cluster_representatives = df_text.groupby('cluster')['designation'].agg(lambda x: x.value_counts().idxmax()).to_dict()\n",
    "\n",
    "# Replace titles and descriptions with their cluster representative\n",
    "df_text['normalized_designation'] = df_text['cluster'].map(cluster_representatives)\n",
    "df_text['normalized_description'] = df_text['cluster'].map(cluster_representatives)\n",
    "\n",
    "# 5. Save the Normalized Data\n",
    "# Save the normalized DataFrame for further use.\n",
    "\n",
    "\n",
    "df_text.to_csv(\"normalized_products.csv\", index=False)\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_titles = df_text[df_text['designation'].str.len()>=240]\n",
    "print(long_titles['designation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Distribution of Product Type Codes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts and sort them\n",
    "sorted_value_counts = df_text['prod_cat_en'].value_counts().sort_values(ascending=False)\n",
    "category_order = sorted_value_counts.index.tolist()\n",
    "\n",
    "\n",
    "# Abbreviate category names\n",
    "abbreviated_labels = [label[:15] + '...' if len(label) > 10 else label for label in category_order]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='prod_cat_en', data=df_text, order=category_order)\n",
    "\n",
    "plt.xticks(ticks=range(len(category_order)), labels=abbreviated_labels, rotation=90)\n",
    "plt.title('Number of Items per Category')\n",
    "plt.xlabel('Product Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have two different versions of the same plot. I find the matplotlib one visually more pleasing plus it is sorted, which makes it easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_type_counts = y_train['prdtypecode'].value_counts()\n",
    "\n",
    "# Plot the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "product_type_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Product Type Codes', fontsize=16)\n",
    "plt.xlabel('Product Type Code', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the product type codes are not equally distibuted. The code 2583 is by far the most represented code with >10k counts. Approximately a third of the rest of the codes have around 4-5k counts, followed by another third with around 3k counts, and the last third with around 1k count each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact percentages of each codes value count is displayed in the following pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    product_type_counts,\n",
    "    autopct='%1.1f%%',  # Display percentages\n",
    "    startangle=90,\n",
    "    colors=plt.cm.tab20.colors,  # Use colormap\n",
    "    textprops={'fontsize': 10},  # Adjust font size for better readability\n",
    "    pctdistance=1.1  # Move percentages outside the pie\n",
    ")\n",
    "\n",
    "# Add a legend outside the pie chart\n",
    "ax.legend(\n",
    "    wedges,\n",
    "    product_type_counts.index,  # Labels for the legend\n",
    "    title=\"Product Type Codes\",\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0, 0.5, 1),  # Position legend outside the chart\n",
    "    fontsize=10\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the distribution on parent category level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the distribution of English parent categories\n",
    "category_distribution = df_text['parent_category_en'].value_counts()\n",
    "\n",
    "# Plot the distribution as a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "category_distribution.plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of English Parent Categories', fontsize=16)\n",
    "plt.xlabel('Parent Category', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Distributions of items without descriptions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe we can also sort this, and use the same style graph as above for unified look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate counts for the filtered DataFrame and sort them in descending order\n",
    "sorted_value_counts = df_text[df_text.isnull().any(axis=1)]['prod_cat_en'].value_counts().sort_values(ascending=False)\n",
    "category_order = sorted_value_counts.index.tolist()\n",
    "\n",
    "# Abbreviate category names\n",
    "abbreviated_labels = [label[:15] + '...' if len(label) > 15 else label for label in category_order]\n",
    "\n",
    "# Create the countplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='prod_cat_en', data=df_text[df_text.isnull().any(axis=1)], order=category_order)\n",
    "\n",
    "# Apply abbreviated labels and rotate them\n",
    "plt.xticks(ticks=range(len(category_order)), labels=abbreviated_labels, rotation=90)\n",
    "plt.title('Countplot of items without descriptions')\n",
    "plt.xlabel('Product Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation?/Observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same graph but on parent category level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for rows with missing descriptions\n",
    "missing_description_df = df_text[df_text.isnull().any(axis=1)]\n",
    "\n",
    "# Plot the count of English parent categories with missing descriptions\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='parent_category_en', data=missing_description_df, palette='viridis')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.title('Countplot of Items Without Descriptions by Parent Category', fontsize=16)\n",
    "plt.xlabel('English Parent Categories', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Distribution of items with description**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe use one style and order descending?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate counts for the filtered DataFrame (rows with descriptions) and sort them in descending order\n",
    "sorted_value_counts_with_desc = df_text[df_text.notnull().all(axis=1)]['prod_cat_en'].value_counts().sort_values(ascending=False)\n",
    "category_order_with_desc = sorted_value_counts_with_desc.index.tolist()\n",
    "\n",
    "# Abbreviate category names\n",
    "abbreviated_labels_with_desc = [label[:15] + '...' if len(label) > 15 else label for label in category_order_with_desc]\n",
    "\n",
    "# Create the countplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='prod_cat_en', data=df_text[df_text.notnull().all(axis=1)], order=category_order_with_desc)\n",
    "\n",
    "# Apply abbreviated labels and rotate them\n",
    "plt.xticks(ticks=range(len(category_order_with_desc)), labels=abbreviated_labels_with_desc, rotation=90)\n",
    "plt.title('Countplot of items with descriptions')\n",
    "plt.xlabel('Product Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation?/Observations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same on parent category level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for rows with descriptions (no missing values)\n",
    "with_description_df = df_text[df_text.notnull().all(axis=1)]\n",
    "\n",
    "# Plot the count of English parent categories with descriptions\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='parent_category_en', data=with_description_df, palette='viridis')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.title('Countplot of Items With Descriptions by Parent Category', fontsize=16)\n",
    "plt.xlabel('English Parent Categories', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Relative distribution of product descriptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total counts and counts with descriptions for each parent category\n",
    "total_counts = df_text['parent_category_en'].value_counts()\n",
    "with_description_counts = df_text[df_text.notnull().all(axis=1)]['parent_category_en'].value_counts()\n",
    "\n",
    "# Calculate the percentage of items with descriptions\n",
    "description_percentage = (with_description_counts / total_counts) * 100\n",
    "\n",
    "# Plot the percentage of items with descriptions\n",
    "plt.figure(figsize=(12, 6))\n",
    "description_percentage.sort_values(ascending=False).plot(kind='bar', color='skyblue')\n",
    "plt.title('Percentage of Items With Descriptions by Parent Category', fontsize=16)\n",
    "plt.xlabel('English Parent Categories', fontsize=14)\n",
    "plt.ylabel('Percentage (%)', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Distribution of Title Lengths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of each product title\n",
    "df_text['title_length'] = df_text['designation'].str.len()\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(\n",
    "    data=df_text,\n",
    "    x='title_length',\n",
    "    bins=25,  # Number of bins for the histogram\n",
    "    kde=True,  # Add a kernel density estimate (smooth curve)\n",
    "    color='skyblue'\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Distribution of Product Title Lengths', fontsize=16)\n",
    "plt.xlabel('Title Length (Number of Characters)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The title lengths follow a somewhat normal and bimodal distributed, but there is a heavy scew to the left, with a bit of a tail to right, getting very thin above 150 characters. Interestingly there is a small spike at around 250 characters. This peak might be due to a maximum allowed length, which also explains why there are no extreme outliers. The rest of the data is distributed around the largest peak in the 40 - 50 character range, and another smaller peak at 80 - 90 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Distribution of description length**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 Histogram of Product Description Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of each product title\n",
    "df_text['description_length'] = df_text['description'].str.len()\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(\n",
    "    data=df_text,\n",
    "    x='description_length',\n",
    "    bins=25,  # Number of bins for the histogram\n",
    "    kde=True,  # Add a kernel density estimate (smooth curve)\n",
    "    color='skyblue'\n",
    ")\n",
    "\n",
    "# Add labels and title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a very long tail with extremely long descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Boxplot of Product Description lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of each product title (if not already done)\n",
    "df_text['description_length'] = df_text['description'].str.len()\n",
    "\n",
    "# Plot the boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    data=df_text,\n",
    "    x='description_length',\n",
    "    color='skyblue'\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Boxplot of Product Description Lengths', fontsize=16)\n",
    "plt.xlabel('Description Length (Number of Characters)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of outliers with extremely long descriptions. Let's take a closer look at the outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR (Interquartile Range)\n",
    "Q1 = df_text['description_length'].quantile(0.25)  # First quartile (25th percentile)\n",
    "Q3 = df_text['description_length'].quantile(0.75)  # Third quartile (75th percentile)\n",
    "IQR = Q3 - Q1  # Interquartile range\n",
    "\n",
    "# Calculate the upper whisker threshold\n",
    "upper_whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "# Count the number of outliers above the upper whisker\n",
    "outliers_above = df_text[df_text['description_length'] > upper_whisker]\n",
    "outlier_count = len(outliers_above)\n",
    "\n",
    "print(f\"The threshold for outliers is {upper_whisker} words in the description.\")\n",
    "print(f\"Number of outliers above the upper whisker: {outlier_count}\")\n",
    "print(f\"Percentage of outliers: {outlier_count / len(df_text) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples of Outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter outliers above the upper whisker\n",
    "outliers_above = df_text[df_text['description_length'] > upper_whisker]\n",
    "\n",
    "# Display the descriptions of 5 outliers\n",
    "print(outliers_above['description'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the descriptions feature a lot of blank spaces. The first description has 160 before the text. Some, but not all outliers seem to have html code in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample of normal length descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR (Interquartile Range)\n",
    "Q1 = df_text['description_length'].quantile(0.25)  # First quartile (25th percentile)\n",
    "Q3 = df_text['description_length'].quantile(0.75)  # Third quartile (75th percentile)\n",
    "IQR = Q3 - Q1  # Interquartile range\n",
    "\n",
    "# Calculate the lower and upper whisker thresholds\n",
    "lower_whisker = Q1 - 1.5 * IQR\n",
    "upper_whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter descriptions within the normal range (inside the box of the boxplot)\n",
    "normal_range = df_text[(df_text['description_length'] >= lower_whisker) & (df_text['description_length'] <= upper_whisker)]\n",
    "\n",
    "# Display 5 descriptions from the normal range\n",
    "print(normal_range['description'].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal lenth code also has a very few html snippets, but much less than the long texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Distribution of descriptions without outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of each product title\n",
    "df_text['description_length'] = df_text['description'].str.len()\n",
    "\n",
    "# Filter the DataFrame for description lengths shorter than 2196.5\n",
    "filtered_df = df_text[df_text['description_length'] < 2196.5]\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(\n",
    "    data=filtered_df,\n",
    "    x='description_length',\n",
    "    bins=25,  # Number of bins for the histogram\n",
    "    kde=True,  # Add a kernel density estimate (smooth curve)\n",
    "    color='skyblue'\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Distribution of Product Description Lengths (< 2196.5)', fontsize=16)\n",
    "plt.xlabel('Title Length (Number of Characters)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's zoom in on the very short descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of each product title\n",
    "df_text['description_length'] = df_text['description'].str.len()\n",
    "\n",
    "# Filter the DataFrame for description lengths shorter than 2196.5\n",
    "filtered_df = df_text[df_text['description_length'] < 100]\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(\n",
    "    data=filtered_df,\n",
    "    x='description_length',\n",
    "    bins=25,  # Number of bins for the histogram\n",
    "    kde=True,  # Add a kernel density estimate (smooth curve)\n",
    "    color='skyblue'\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Distribution of Product Description Lengths (< 2196.5)', fontsize=16)\n",
    "plt.xlabel('Title Length (Number of Characters)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us take a look at very short descriptions, though they are not technically outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter outliers above the upper whisker\n",
    "outliers_above = df_text[df_text['description_length'] < 30]\n",
    "\n",
    "# Display the descriptions of 5 outliers\n",
    "print(outliers_above['description'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some descriptions are essentially NaNs (e.g.) \"<br / >\", others seem to only add little information to the title (\"designation\"). More clear after cleaning and merger of title and description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Word Clouds of descriptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_viz import word_cloud\n",
    "word_cloud(df_text, 'prdtypecode', 'description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Word Clouds of designation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud(df_text, 'prdtypecode', 'designation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much text did we save by cleaning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of characters in df_text['description'] and df_text['designation']\n",
    "total_description_chars = df_text['description'].str.len().sum()\n",
    "total_designation_chars = df_text['designation'].str.len().sum()\n",
    "\n",
    "# Calculate the total number of characters in df_merge['text_merged']\n",
    "total_text_merged_chars = df_merge['text_merged'].str.len().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total characters in df_text['description']: {total_description_chars:,}\")\n",
    "print(f\"Total characters in df_text['designation']: {total_designation_chars:,}\")\n",
    "print(f\"Total characters in df_merge['text_merged']: {total_text_merged_chars:,}\")\n",
    "\n",
    "# Compare the totals\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"Sum of df_text['description'] and df_text['designation']: {total_description_chars + total_designation_chars:,}\")\n",
    "print(f\"Total characters in df_merge['text_merged']: {total_text_merged_chars:,}\")\n",
    "print(f\"relative difference: {abs(total_description_chars + total_designation_chars - total_text_merged_chars) / (total_description_chars + total_designation_chars) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the length of strings in df_merge['text_merged']\n",
    "text_lengths = df_merge['text_merged'].str.len()\n",
    "\n",
    "# Create a boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=text_lengths, color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Boxplot of String Lengths in df_merge[\"text_merged\"]', fontsize=14)\n",
    "plt.xlabel('Length of Strings', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the length of strings in df_merge['text_merged']\n",
    "text_lengths = df_merge['description_cleaned'].str.len()\n",
    "\n",
    "# Create a boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=text_lengths, color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Boxplot of String Lengths in df_merge[\"description_cleaned\"]', fontsize=14)\n",
    "plt.xlabel('Length of Strings', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR (Interquartile Range)\n",
    "Q1 = text_lengths.quantile(0.25)  # First quartile (25th percentile)\n",
    "Q3 = text_lengths.quantile(0.75)  # Third quartile (75th percentile)\n",
    "IQR = Q3 - Q1  # Interquartile range\n",
    "\n",
    "# Calculate the upper whisker threshold\n",
    "upper_whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "# Count the number of outliers above the upper whisker\n",
    "outliers_above = df_text[text_lengths > upper_whisker]\n",
    "outlier_count = len(outliers_above)\n",
    "\n",
    "print(f\"The threshold for outliers is {upper_whisker} words in the description.\")\n",
    "print(f\"Number of outliers above the upper whisker: {outlier_count}\")\n",
    "print(f\"Percentage of outliers: {outlier_count / len(df_text) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'parent_category_en' and count the number of outliers\n",
    "outliers_by_category = outliers_above.groupby('parent_category_en').size()\n",
    "\n",
    "# Plot the results as a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "outliers_by_category.sort_values(ascending=False).plot(kind='bar', color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Count of Outliers (Above Upper Whisker) by Parent Category', fontsize=14)\n",
    "plt.xlabel('Parent Category', fontsize=12)\n",
    "plt.ylabel('Count of Outliers', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print additional information\n",
    "print(f\"The threshold for outliers is {upper_whisker} characters in the description.\")\n",
    "print(f\"Number of outliers above the upper whisker: {len(outliers_above)}\")\n",
    "print(f\"Percentage of outliers: {len(outliers_above) / len(df_text) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_titles = df_text[df_text['designation'].str.len()>=240]\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "# Peter 31mar2025: I would set this option in the setup section of the notebook after all imports\n",
    "print(long_titles['designation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of duplicate entries in df_merge['text_merged']\n",
    "num_duplicates = df_merge['text_merged'].duplicated().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of duplicate entries in df_merge['text_merged']: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on 'designation_cleaned' and 'description_cleaned', keeping only the first occurrence\n",
    "unique_df = df_merge.drop_duplicates(subset=['designation_cleaned', 'description_cleaned'])\n",
    "\n",
    "# Calculate the total number of characters for the unique entries\n",
    "total_designation_cleaned_chars = unique_df['designation_cleaned'].str.len().sum()\n",
    "total_description_cleaned_chars = unique_df['description_cleaned'].str.len().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total characters in unique df_merge['designation_cleaned'] + df_merge['description_cleaned']: {total_designation_cleaned_chars + total_description_cleaned_chars:,}\")\n",
    "print(f\"relative difference of clean and unique entries to original text length: {abs(total_description_chars + total_designation_chars - (total_designation_cleaned_chars + total_description_cleaned_chars)) / (total_description_chars + total_designation_chars) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can only translate the unique entries of the cleaned descriptions and titles ('designation'), before they are merged, we can save around 9% of characters maximum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_descriptions = df_merge[df_merge['description_cleaned'].str.len()>=2200]\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "# Peter 31mar2025: I would set this option in the setup section of the notebook after all imports\n",
    "display(long_descriptions['description_cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think to clean the description also did not work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11 = df_merge.iloc[[11]][['designation', 'description','designation_cleaned', 'description_cleaned', 'text_merged']]\n",
    "\n",
    "for index, row in df_11.iterrows():\n",
    "    print(f\"Row:\\n\\t{index}\")\n",
    "    print(f\"Designation:\\n\\t'{row['designation']}'\")\n",
    "    print(f\"Description:\\n\\t'{row['description']}'\")\n",
    "    print(f\"Cleaned Designation:\\n\\t'{row['designation_cleaned']}'\")\n",
    "    print(f\"Cleaned Description:\\n\\t'{row['description_cleaned']}'\")\n",
    "    print(f\"Merged Text:\\n\\t'{row['text_merged']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much text did we save by cleaning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of characters in df_text['description'] and df_text['designation']\n",
    "total_description_chars = df_text['description'].str.len().sum()\n",
    "total_designation_chars = df_text['designation'].str.len().sum()\n",
    "\n",
    "# Calculate the total number of characters in df_merge['text_merged']\n",
    "total_text_merged_chars = df_merge['text_merged'].str.len().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total characters in df_text['description']: {total_description_chars:,}\")\n",
    "print(f\"Total characters in df_text['designation']: {total_designation_chars:,}\")\n",
    "print(f\"Total characters in df_merge['text_merged']: {total_text_merged_chars:,}\")\n",
    "\n",
    "# Compare the totals\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"Sum of df_text['description'] and df_text['designation']: {total_description_chars + total_designation_chars:,}\")\n",
    "print(f\"Total characters in df_merge['text_merged']: {total_text_merged_chars:,}\")\n",
    "print(f\"relative difference: {abs(total_description_chars + total_designation_chars - total_text_merged_chars) / (total_description_chars + total_designation_chars) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the length of strings in df_merge['text_merged']\n",
    "text_lengths = df_merge['text_merged'].str.len()\n",
    "\n",
    "# Create a boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=text_lengths, color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Boxplot of String Lengths in df_merge[\"text_merged\"]', fontsize=14)\n",
    "plt.xlabel('Length of Strings', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the length of strings in df_merge['text_merged']\n",
    "text_lengths = df_merge['description_cleaned'].str.len()\n",
    "\n",
    "# Create a boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=text_lengths, color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Boxplot of String Lengths in df_merge[\"description_cleaned\"]', fontsize=14)\n",
    "plt.xlabel('Length of Strings', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR (Interquartile Range)\n",
    "Q1 = text_lengths.quantile(0.25)  # First quartile (25th percentile)\n",
    "Q3 = text_lengths.quantile(0.75)  # Third quartile (75th percentile)\n",
    "IQR = Q3 - Q1  # Interquartile range\n",
    "\n",
    "# Calculate the upper whisker threshold\n",
    "upper_whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "# Count the number of outliers above the upper whisker\n",
    "outliers_above = df_text[text_lengths > upper_whisker]\n",
    "outlier_count = len(outliers_above)\n",
    "\n",
    "print(f\"The threshold for outliers is {upper_whisker} words in the description.\")\n",
    "print(f\"Number of outliers above the upper whisker: {outlier_count}\")\n",
    "print(f\"Percentage of outliers: {outlier_count / len(df_text) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'parent_category_en' and count the number of outliers\n",
    "outliers_by_category = outliers_above.groupby('parent_category_en').size()\n",
    "\n",
    "# Plot the results as a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "outliers_by_category.sort_values(ascending=False).plot(kind='bar', color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Count of Outliers (Above Upper Whisker) by Parent Category', fontsize=14)\n",
    "plt.xlabel('Parent Category', fontsize=12)\n",
    "plt.ylabel('Count of Outliers', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print additional information\n",
    "print(f\"The threshold for outliers is {upper_whisker} characters in the description.\")\n",
    "print(f\"Number of outliers above the upper whisker: {len(outliers_above)}\")\n",
    "print(f\"Percentage of outliers: {len(outliers_above) / len(df_text) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_titles = df_text[df_text['designation'].str.len()>=240]\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "# Peter 31mar2025: I would set this option in the setup section of the notebook after all imports\n",
    "print(long_titles['designation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of duplicate entries in df_merge['text_merged']\n",
    "num_duplicates = df_merge['text_merged'].duplicated().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of duplicate entries in df_merge['text_merged']: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on 'designation_cleaned' and 'description_cleaned', keeping only the first occurrence\n",
    "unique_df = df_merge.drop_duplicates(subset=['designation_cleaned', 'description_cleaned'])\n",
    "\n",
    "# Calculate the total number of characters for the unique entries\n",
    "total_designation_cleaned_chars = unique_df['designation_cleaned'].str.len().sum()\n",
    "total_description_cleaned_chars = unique_df['description_cleaned'].str.len().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total characters in unique df_merge['designation_cleaned'] + df_merge['description_cleaned']: {total_designation_cleaned_chars + total_description_cleaned_chars:,}\")\n",
    "print(f\"relative difference of clean and unique entries to original text length: {abs(total_description_chars + total_designation_chars - (total_designation_cleaned_chars + total_description_cleaned_chars)) / (total_description_chars + total_designation_chars) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can only translate the unique entries of the cleaned descriptions and titles ('designation'), before they are merged, we can save around 9% of characters maximum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_descriptions = df_merge[df_merge['description_cleaned'].str.len()>=2200]\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "# Peter 31mar2025: I would set this option in the setup section of the notebook after all imports\n",
    "display(long_descriptions['description_cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think to clean the description also did not work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11 = df_merge.iloc[[11]][['designation', 'description','designation_cleaned', 'description_cleaned', 'text_merged']]\n",
    "\n",
    "for index, row in df_11.iterrows():\n",
    "    print(f\"Row:\\n\\t{index}\")\n",
    "    print(f\"Designation:\\n\\t'{row['designation']}'\")\n",
    "    print(f\"Description:\\n\\t'{row['description']}'\")\n",
    "    print(f\"Cleaned Designation:\\n\\t'{row['designation_cleaned']}'\")\n",
    "    print(f\"Cleaned Description:\\n\\t'{row['description_cleaned']}'\")\n",
    "    print(f\"Merged Text:\\n\\t'{row['text_merged']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much text did we save by cleaning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of characters in df_text['description'] and df_text['designation']\n",
    "total_description_chars = df_text['description'].str.len().sum()\n",
    "total_designation_chars = df_text['designation'].str.len().sum()\n",
    "\n",
    "# Calculate the total number of characters in df_merge['text_merged']\n",
    "total_text_merged_chars = df_merge['text_merged'].str.len().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total characters in df_text['description']: {total_description_chars:,}\")\n",
    "print(f\"Total characters in df_text['designation']: {total_designation_chars:,}\")\n",
    "print(f\"Total characters in df_merge['text_merged']: {total_text_merged_chars:,}\")\n",
    "\n",
    "# Compare the totals\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"Sum of df_text['description'] and df_text['designation']: {total_description_chars + total_designation_chars:,}\")\n",
    "print(f\"Total characters in df_merge['text_merged']: {total_text_merged_chars:,}\")\n",
    "print(f\"relative difference: {abs(total_description_chars + total_designation_chars - total_text_merged_chars) / (total_description_chars + total_designation_chars) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the length of strings in df_merge['text_merged']\n",
    "text_lengths = df_merge['text_merged'].str.len()\n",
    "\n",
    "# Create a boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=text_lengths, color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Boxplot of String Lengths in df_merge[\"text_merged\"]', fontsize=14)\n",
    "plt.xlabel('Length of Strings', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the length of strings in df_merge['text_merged']\n",
    "text_lengths = df_merge['description_cleaned'].str.len()\n",
    "\n",
    "# Create a boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=text_lengths, color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Boxplot of String Lengths in df_merge[\"description_cleaned\"]', fontsize=14)\n",
    "plt.xlabel('Length of Strings', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR (Interquartile Range)\n",
    "Q1 = text_lengths.quantile(0.25)  # First quartile (25th percentile)\n",
    "Q3 = text_lengths.quantile(0.75)  # Third quartile (75th percentile)\n",
    "IQR = Q3 - Q1  # Interquartile range\n",
    "\n",
    "# Calculate the upper whisker threshold\n",
    "upper_whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "# Count the number of outliers above the upper whisker\n",
    "outliers_above = df_text[text_lengths > upper_whisker]\n",
    "outlier_count = len(outliers_above)\n",
    "\n",
    "print(f\"The threshold for outliers is {upper_whisker} words in the description.\")\n",
    "print(f\"Number of outliers above the upper whisker: {outlier_count}\")\n",
    "print(f\"Percentage of outliers: {outlier_count / len(df_text) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'parent_category_en' and count the number of outliers\n",
    "outliers_by_category = outliers_above.groupby('parent_category_en').size()\n",
    "\n",
    "# Plot the results as a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "outliers_by_category.sort_values(ascending=False).plot(kind='bar', color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Count of Outliers (Above Upper Whisker) by Parent Category', fontsize=14)\n",
    "plt.xlabel('Parent Category', fontsize=12)\n",
    "plt.ylabel('Count of Outliers', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print additional information\n",
    "print(f\"The threshold for outliers is {upper_whisker} characters in the description.\")\n",
    "print(f\"Number of outliers above the upper whisker: {len(outliers_above)}\")\n",
    "print(f\"Percentage of outliers: {len(outliers_above) / len(df_text) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_titles = df_text[df_text['designation'].str.len()>=240]\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "# Peter 31mar2025: I would set this option in the setup section of the notebook after all imports\n",
    "print(long_titles['designation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of duplicate entries in df_merge['text_merged']\n",
    "num_duplicates = df_merge['text_merged'].duplicated().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of duplicate entries in df_merge['text_merged']: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on 'designation_cleaned' and 'description_cleaned', keeping only the first occurrence\n",
    "unique_df = df_merge.drop_duplicates(subset=['designation_cleaned', 'description_cleaned'])\n",
    "\n",
    "# Calculate the total number of characters for the unique entries\n",
    "total_designation_cleaned_chars = unique_df['designation_cleaned'].str.len().sum()\n",
    "total_description_cleaned_chars = unique_df['description_cleaned'].str.len().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total characters in unique df_merge['designation_cleaned'] + df_merge['description_cleaned']: {total_designation_cleaned_chars + total_description_cleaned_chars:,}\")\n",
    "print(f\"relative difference of clean and unique entries to original text length: {abs(total_description_chars + total_designation_chars - (total_designation_cleaned_chars + total_description_cleaned_chars)) / (total_description_chars + total_designation_chars) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can only translate the unique entries of the cleaned descriptions and titles ('designation'), before they are merged, we can save around 9% of characters maximum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_descriptions = df_merge[df_merge['description_cleaned'].str.len()>=2200]\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "# Peter 31mar2025: I would set this option in the setup section of the notebook after all imports\n",
    "display(long_descriptions['description_cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think to clean the description also did not work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11 = df_merge.iloc[[11]][['designation', 'description','designation_cleaned', 'description_cleaned', 'text_merged']]\n",
    "\n",
    "for index, row in df_11.iterrows():\n",
    "    print(f\"Row:\\n\\t{index}\")\n",
    "    print(f\"Designation:\\n\\t'{row['designation']}'\")\n",
    "    print(f\"Description:\\n\\t'{row['description']}'\")\n",
    "    print(f\"Cleaned Designation:\\n\\t'{row['designation_cleaned']}'\")\n",
    "    print(f\"Cleaned Description:\\n\\t'{row['description_cleaned']}'\")\n",
    "    print(f\"Merged Text:\\n\\t'{row['text_merged']}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
