{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Setup\n",
                "1. Import modules\n",
                "2. Explore datasets: feature data, training data\n",
                "3. Data cleaning:\n",
                "    1. Text cleaning\n",
                "    2. Text normalization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install -qr \"requirements.txt\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import re\n",
                "\n",
                "from text_utils import text_cleaner, text_merger\n",
                "from image_utils import image_data_extractor, detect_bounding_box_parallel, crop_pad_and_resize_image_parallel, find_duplicates_parallel, create_duplicates_dataframe\n",
                "\n",
                "X_train = pd.read_csv(\"X_train.csv\", index_col=0)\n",
                "X_test = pd.read_csv(\"X_test.csv\", index_col=0)\n",
                "y_train = pd.read_csv(\"y_train.csv\", index_col=0)\n",
                "\n",
                "# Create DataFrame for text data like 'designation' and 'decription'\n",
                "df_text_train = pd.merge(X_train, y_train, left_index=True, right_index=True)\n",
                "df_text_train = df_text_train.set_index(keys=\"productid\")\n",
                "df_text_test = pd.read_csv(\"X_test.csv\", index_col=\"productid\", usecols=[\"productid\", \"imageid\", \"designation\", \"description\"])\n",
                "\n",
                "# Create DataFrames for image data\n",
                "df_image_train = df_text_train.drop(columns=[\"designation\", \"description\"])\n",
                "df_image_test = pd.read_csv(\"X_test.csv\", index_col=\"productid\", usecols=[\"productid\", \"imageid\"])\n",
                "\n",
                "#df_text_train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Exploration of text data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Display basic **information** about the text data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Index: 84916 entries, 3804725264 to 57203227\n",
                        "Data columns (total 4 columns):\n",
                        " #   Column       Non-Null Count  Dtype \n",
                        "---  ------       --------------  ----- \n",
                        " 0   designation  84916 non-null  object\n",
                        " 1   description  55116 non-null  object\n",
                        " 2   imageid      84916 non-null  int64 \n",
                        " 3   prdtypecode  84916 non-null  int64 \n",
                        "dtypes: int64(2), object(2)\n",
                        "memory usage: 3.2+ MB\n",
                        "None\n"
                    ]
                }
            ],
            "source": [
                "print(df_text_train.info())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** What is the size of the original dataset for training?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The original dataset contains a total of 339,664 cells.\n",
                        "\n",
                        "The data are distributed over 84,916 products with 4 attributes:\n",
                        "\t1. designation\n",
                        "\t2. description\n",
                        "\t3. imageid\n",
                        "\t4. prdtypecode\n"
                    ]
                }
            ],
            "source": [
                "# Get size of DataFrame\n",
                "cells = df_text_train.size\n",
                "\n",
                "# Get shape of DataFrame in order to get number of rows (products) and columns (attributes)\n",
                "df_text_train.shape\n",
                "\n",
                "rows = df_text_train.shape[0]\n",
                "cols = df_text_train.shape[1]\n",
                "\n",
                "print(f'The original dataset contains a total of {cells:,} cells.', end='\\n\\n')\n",
                "print(f'The data are distributed over {rows:,} products with {cols} attributes:')\n",
                "\n",
                "# Get names of columns for better understanding of attributes\n",
                "column_names = df_text_train.columns\n",
                "\n",
                "for nr, cn in enumerate(column_names, start=1): # nr as in \"number\", cn as in \"column name\"\n",
                "    print(f'\\t{nr}. {cn}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** Are there any missing values (NaN)?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The original data set has missing descriptions:\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "designation    False\n",
                            "description     True\n",
                            "imageid        False\n",
                            "prdtypecode    False\n",
                            "dtype: bool"
                        ]
                    },
                    "execution_count": 57,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "print('The original data set has missing descriptions:')\n",
                "\n",
                "df_text_train.isna().any()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** How many missing values are we looking at?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The training data has 29,800 missing values in the column 'description'.\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "designation        0\n",
                            "description    29800\n",
                            "imageid            0\n",
                            "prdtypecode        0\n",
                            "dtype: int64"
                        ]
                    },
                    "execution_count": 58,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "description_nan = df_text_train['description'].isna()\n",
                "description_nan_amt = description_nan.sum()\n",
                "\n",
                "print(f'The training data has {description_nan_amt:,} missing values in the column \\'description\\'.')\n",
                "\n",
                "df_text_train.isna().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Duplicate values\n",
                "Step 2 // Preprocessing: Duplicate items [[Issue #16]](https://github.com/PeterStieg/feb25_bds_classification-of-rakuten-e-commerce-products/issues/16)\n",
                "- Amount of duplicate values per column (attribute)\n",
                "- Most frequent product titles (designation)\n",
                "- Most frequent product description"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** Are there any duplicate values?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The column \u001b[1m'designation'\u001b[0m has 2,651 duplicate values: 3.12%\n",
                        "The column \u001b[1m'description'\u001b[0m has 37,409 duplicate values: 44.05%\n",
                        "The column \u001b[1m'prdtypecode'\u001b[0m has 84,889 duplicate values: 99.97%\n"
                    ]
                }
            ],
            "source": [
                "duplicate_values = {}\n",
                "\n",
                "for cn in column_names:\n",
                "   cn_duplicates = df_text_train[cn].duplicated().sum()\n",
                "   \n",
                "   if cn_duplicates:\n",
                "      pct = cn_duplicates / rows\n",
                "      print(f'The column \\033[1m\\'{cn}\\'\\033[0m has {cn_duplicates:,} duplicate values: {pct:.2%}')\n",
                "      \n",
                "      # Add data to dictionary for later comparison\n",
                "      duplicate_values[cn] = [int(cn_duplicates), round(pct, 2)]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** What are the most common duplicate values for product titles (designation)?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "designation\n",
                        "5d Broderie Peintures Strass Diamant Bricolage Pasted Peinture Point De Croix       76\n",
                        "Simple Linen Creative Belle Oreiller Taie D'oreiller Taie D'oreiller Car Cover      28\n",
                        "Cotton Linen Place Décoratifs Pour La Maison Coussin Case Canapé Taille Coussin     25\n",
                        "Imprimer Taie Polyester Canapé Coussin Car Cover Home Decor                         22\n",
                        "Joyeuse Saint-Valentin Jetez Taie D'oreiller Sweet Love Coussin Carré Couverture    21\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "designation_value_counts = df_text_train['designation'].value_counts().sort_values(ascending=False)\n",
                "designation_value_counts_top5 = designation_value_counts.iloc[:5]\n",
                "print(designation_value_counts_top5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** What are the most common duplicate values for product descriptions?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "description\n",
                        "<br>Attention !!! Ce produit est un import  si les informations 'langues' et 'sous-titres' n'apparaissent pas sur cette fiche produit c'est que l'éditeur ne nous les a pas fournies. Néanmoins dans la grande majorité de ces cas il n'existe ni langue ni sous titres en français sur ces imports.    252\n",
                        "Taille: En format A5 (144 cm x 21 cm) Caractéistique: -Excellente durabilité avec couverture solide design. 96 pages jaune pale (recto et verso) -Texture de papier de haute qualitévous pouvez y érire facilement                                                                                      232\n",
                        "Taille: En format A5 (144 cm x 21 cm) Caracteristique: -Excellente durabilite avec couverture solide design. 96 pages jaune pale (recto et verso) -Texture de papier de haute qualite:  ecrire facilement sur et assez epaisse.                                                                         189\n",
                        "Taille: En format A5 (144 cm x 21 cm) Caract?istique: -Excellente durabilit?avec couverture solide design. 96 pages jaune pale (recto et verso) -Texture de papier de haute qualit?  ?rire facilement sur et assez ?aisse.                                                                              162\n",
                        "Taille: En format A5 (144 cm x 21 cm) Caractéristique: -Excellente durabilit?avec couverture solide design. 96 pages jaune pale (recto et verso) -Texture de papier de haute qualit?  écrire facilement sur et assez épaisse.                                                                            89\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "description_value_counts = df_text_train['description'].value_counts().sort_values(ascending=False)\n",
                "description_value_counts_top5 = description_value_counts.iloc[:5]\n",
                "print(description_value_counts_top5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** How many products with missing descriptions have duplicated designations?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get rows of DataFrame with missing descriptions\n",
                "df_descr_nan = df_text_train[description_nan] # filter defined in 'Exploration of text data'\n",
                "\n",
                "# Get number of rows with duplicate titles (designation)\n",
                "missDescription_duplTitle_amt = df_descr_nan['designation'].duplicated().sum()\n",
                "\n",
                "print(f'Only {missDescription_duplTitle_amt:,} products with a missing description have a duplicate title (designation).', end='\\n\\n')\n",
                "print(f'Compared to a total of {description_nan_amt:,} products with a missing description, this is only {missDescription_duplTitle_amt / description_nan_amt:.2%} of the total.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** Does the number of duplicate titles and descriptions increase after **cleaning the string variables?**\n",
                "\n",
                "**Proprecessing steps** with function *text_cleaner()* from text_utils.py, which\n",
                "1. Removes:\n",
                "    1. Leading and trailing spaces \n",
                "    2. HTML tags, e.g. \\<br>, \\<br />, \\<b>\n",
                "\n",
                "2. Replaces:\n",
                "    1. HTML entities with their corresponding characters, e.g. &eacute; → è, &auml; → ä, &ntilde; → ñ \n",
                "    2. Control characters with empty strings, e.g. Ã, Â©, �\n",
                "    3. Multiple spaces with a single space"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create new DataFrame with cleaned text columns\n",
                "\n",
                "#df_text_train_clean = text_cleaner(df_text_train) # Duration 10may2025: 47s\n",
                "#df_text_train_clean.to_parquet('df_text_train_clean.parquet', index=True)\n",
                "#df_text_train_clean.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Questions:**\n",
                "1. What do the cleaned strings look like?\n",
                "2. How many characters did we save by cleaning strings?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1mDesignation\u001b[0m:\n",
                        "\tTotal length of designation: 5,957,987\n",
                        "\tTotal length of cleaned designation: 5,924,420\n",
                        "\tAmount of saved chars in designation: 33,567\n",
                        "\n",
                        "\u001b[1mDescription\u001b[0m:\n",
                        "\tTotal length of description: 44,543,191.0\n",
                        "\tTotal length of cleaned description: 41,335,283\n",
                        "\tAmount of saved chars in description: 3,207,908.0\n",
                        "\n",
                        "\u001b[1mSummary\u001b[0m:\n",
                        "\tTotal amount of saved chars: 3,241,475.0 (6.42%)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>designation</th>\n",
                            "      <th>designation_cleaned</th>\n",
                            "      <th>designation_len</th>\n",
                            "      <th>designation_cleaned_len</th>\n",
                            "      <th>designation_saved_len</th>\n",
                            "      <th>description</th>\n",
                            "      <th>description_cleaned</th>\n",
                            "      <th>description_len</th>\n",
                            "      <th>description_cleaned_len</th>\n",
                            "      <th>description_saved_len</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>productid</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>4017682069</th>\n",
                            "      <td>S101 2.4ghz Fpv Wifi 2mp 720p Pression D'air C...</td>\n",
                            "      <td>S101 2.4ghz Fpv Wifi 2mp 720p Pression D'air C...</td>\n",
                            "      <td>90</td>\n",
                            "      <td>90</td>\n",
                            "      <td>0</td>\n",
                            "      <td>S101 24 FPV Wifi 720P ?????????????? ?????? ??...</td>\n",
                            "      <td>S101 24 FPV Wifi 720P RC Drone Quadcopter &amp; NB...</td>\n",
                            "      <td>5037.0</td>\n",
                            "      <td>1048</td>\n",
                            "      <td>3989.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1846458171</th>\n",
                            "      <td>Huile essentielle de Fleur d'Oranger Aromathér...</td>\n",
                            "      <td>Huile essentielle de Fleur d'Oranger Aromathér...</td>\n",
                            "      <td>62</td>\n",
                            "      <td>62</td>\n",
                            "      <td>0</td>\n",
                            "      <td>&lt;div class=\"box-collateral-content\"&gt; &lt;div clas...</td>\n",
                            "      <td>Huile Essentielle de Fleur d'Oranger Hydrosolu...</td>\n",
                            "      <td>3999.0</td>\n",
                            "      <td>755</td>\n",
                            "      <td>3244.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1838575231</th>\n",
                            "      <td>Huile essentielle de Pin Aromathérapie Spa Jac...</td>\n",
                            "      <td>Huile essentielle de Pin Aromathérapie Spa Jac...</td>\n",
                            "      <td>50</td>\n",
                            "      <td>50</td>\n",
                            "      <td>0</td>\n",
                            "      <td>&lt;div class=\"box-collateral-content\"&gt; &lt;div clas...</td>\n",
                            "      <td>Huile Essentielle d'Eucalyptus Hydrosoluble po...</td>\n",
                            "      <td>3997.0</td>\n",
                            "      <td>902</td>\n",
                            "      <td>3095.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1838575225</th>\n",
                            "      <td>Huile essentielle Eucalyptus Aromathérapie Spa...</td>\n",
                            "      <td>Huile essentielle Eucalyptus Aromathérapie Spa...</td>\n",
                            "      <td>54</td>\n",
                            "      <td>54</td>\n",
                            "      <td>0</td>\n",
                            "      <td>&lt;div class=\"box-collateral-content\"&gt; &lt;div clas...</td>\n",
                            "      <td>Huile Essentielle d'Eucalyptus Hydrosoluble po...</td>\n",
                            "      <td>3997.0</td>\n",
                            "      <td>902</td>\n",
                            "      <td>3095.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1838575207</th>\n",
                            "      <td>Huiles essentielles Elinya Aromathérapie Spa J...</td>\n",
                            "      <td>Huiles essentielles Elinya Aromathérapie Spa J...</td>\n",
                            "      <td>52</td>\n",
                            "      <td>52</td>\n",
                            "      <td>0</td>\n",
                            "      <td>&lt;div class=\"box-collateral-content\"&gt; &lt;div clas...</td>\n",
                            "      <td>Huiles Essentielles Elinya Hydrosoluble pour S...</td>\n",
                            "      <td>3991.0</td>\n",
                            "      <td>1030</td>\n",
                            "      <td>2961.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                  designation  \\\n",
                            "productid                                                       \n",
                            "4017682069  S101 2.4ghz Fpv Wifi 2mp 720p Pression D'air C...   \n",
                            "1846458171  Huile essentielle de Fleur d'Oranger Aromathér...   \n",
                            "1838575231  Huile essentielle de Pin Aromathérapie Spa Jac...   \n",
                            "1838575225  Huile essentielle Eucalyptus Aromathérapie Spa...   \n",
                            "1838575207  Huiles essentielles Elinya Aromathérapie Spa J...   \n",
                            "\n",
                            "                                          designation_cleaned  \\\n",
                            "productid                                                       \n",
                            "4017682069  S101 2.4ghz Fpv Wifi 2mp 720p Pression D'air C...   \n",
                            "1846458171  Huile essentielle de Fleur d'Oranger Aromathér...   \n",
                            "1838575231  Huile essentielle de Pin Aromathérapie Spa Jac...   \n",
                            "1838575225  Huile essentielle Eucalyptus Aromathérapie Spa...   \n",
                            "1838575207  Huiles essentielles Elinya Aromathérapie Spa J...   \n",
                            "\n",
                            "            designation_len  designation_cleaned_len  designation_saved_len  \\\n",
                            "productid                                                                     \n",
                            "4017682069               90                       90                      0   \n",
                            "1846458171               62                       62                      0   \n",
                            "1838575231               50                       50                      0   \n",
                            "1838575225               54                       54                      0   \n",
                            "1838575207               52                       52                      0   \n",
                            "\n",
                            "                                                  description  \\\n",
                            "productid                                                       \n",
                            "4017682069  S101 24 FPV Wifi 720P ?????????????? ?????? ??...   \n",
                            "1846458171  <div class=\"box-collateral-content\"> <div clas...   \n",
                            "1838575231  <div class=\"box-collateral-content\"> <div clas...   \n",
                            "1838575225  <div class=\"box-collateral-content\"> <div clas...   \n",
                            "1838575207  <div class=\"box-collateral-content\"> <div clas...   \n",
                            "\n",
                            "                                          description_cleaned  \\\n",
                            "productid                                                       \n",
                            "4017682069  S101 24 FPV Wifi 720P RC Drone Quadcopter & NB...   \n",
                            "1846458171  Huile Essentielle de Fleur d'Oranger Hydrosolu...   \n",
                            "1838575231  Huile Essentielle d'Eucalyptus Hydrosoluble po...   \n",
                            "1838575225  Huile Essentielle d'Eucalyptus Hydrosoluble po...   \n",
                            "1838575207  Huiles Essentielles Elinya Hydrosoluble pour S...   \n",
                            "\n",
                            "            description_len  description_cleaned_len  description_saved_len  \n",
                            "productid                                                                    \n",
                            "4017682069           5037.0                     1048                 3989.0  \n",
                            "1846458171           3999.0                      755                 3244.0  \n",
                            "1838575231           3997.0                      902                 3095.0  \n",
                            "1838575225           3997.0                      902                 3095.0  \n",
                            "1838575207           3991.0                     1030                 2961.0  "
                        ]
                    },
                    "execution_count": 69,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_text_train_clean = pd.read_parquet('df_text_train_clean.parquet')\n",
                "df_text_train_copy = df_text_train_clean.copy()\n",
                "\n",
                "df_text_train_len = df_text_train_copy[[\"designation\", \"designation_cleaned\", \"designation_len\", \"designation_cleaned_len\", \"designation_saved_len\", \"description\", \"description_cleaned\", \"description_len\", \"description_cleaned_len\", \"description_saved_len\"]]\n",
                "\n",
                "designation_len = df_text_train_len['designation_len'].sum()\n",
                "description_len = df_text_train_len['description_len'].sum()\n",
                "designation_saved_len = df_text_train_len['designation_saved_len'].sum()\n",
                "\n",
                "designation_cleaned_len = df_text_train_len['designation_cleaned_len'].sum()\n",
                "description_cleaned_len = df_text_train_len['description_cleaned_len'].sum()\n",
                "description_saved_len = df_text_train_len['description_saved_len'].sum()\n",
                "\n",
                "pct_saved = (designation_saved_len + description_saved_len) / (designation_len + description_len) * 100\n",
                "\n",
                "print(f\"\\033[1mDesignation\\033[0m:\")\n",
                "print(f\"\\tTotal length of designation: {designation_len:,}\")\n",
                "print(f\"\\tTotal length of cleaned designation: {designation_cleaned_len:,}\")\n",
                "print(f\"\\tAmount of saved chars in designation: {designation_saved_len:,}\", end=\"\\n\\n\")\n",
                "\n",
                "print(f\"\\033[1mDescription\\033[0m:\")\n",
                "print(f\"\\tTotal length of description: {description_len:,}\")\n",
                "print(f\"\\tTotal length of cleaned description: {description_cleaned_len:,}\")\n",
                "print(f\"\\tAmount of saved chars in description: {description_saved_len:,}\", end=\"\\n\\n\")\n",
                "\n",
                "print(f\"\\033[1mSummary\\033[0m:\")\n",
                "print(f\"\\tTotal amount of saved chars: {designation_saved_len + description_saved_len:,} ({pct_saved:.2f}%)\")\n",
                "\n",
                "df_text_len_sorted = df_text_train_len.sort_values(by = \"description_saved_len\", ascending=False)\n",
                "\n",
                "df_text_len_sorted.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Comparison** of number of duplicates in the orig. and cleaned DataFrame"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The cleaned column \u001b[1m'designation_cleaned'\u001b[0m has...\n",
                        "\t2,657 duplicates compared to 2,651 (+6)\n",
                        "\tAn increase of 0.13% from 3.00% to 3.13%\n",
                        "\n",
                        "The cleaned column \u001b[1m'description_cleaned'\u001b[0m has...\n",
                        "\t37,614 duplicates compared to 37,409 (+205)\n",
                        "\tAn increase of 0.30% from 44.00% to 44.30%\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "text_cols = ['designation_cleaned', 'description_cleaned']\n",
                "\n",
                "for cn_clean in text_cols:\n",
                "  cn_duplicates = df_text_train_clean[cn_clean].duplicated().sum()\n",
                "  pct = cn_duplicates / rows\n",
                "\n",
                "  # Get the previous value from the dictionary\n",
                "  \n",
                "  cn = re.sub('_cleaned', '', cn_clean)\n",
                "  pct_incr = pct - duplicate_values[cn][1]\n",
                "\n",
                "  print(f'The cleaned column \\033[1m\\'{cn_clean}\\'\\033[0m has...')\n",
                "  print(f'\\t{cn_duplicates:,} duplicates compared to {duplicate_values[cn][0]:,} (+{cn_duplicates - duplicate_values[cn][0]:,})')\n",
                "  print(f'\\tAn increase of {pct_incr:.2%} from {duplicate_values[cn][1]:.2%} to {pct:.2%}', end='\\n\\n')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** Does the number of identical original string variables differ from cleaned string variables?\n",
                "\n",
                "**Proprecessing steps** with function *text_merger()* from text_utils.py:\n",
                "1. Compare original string variables and set flags\n",
                "2. Compare cleaned string variables and set flags\n",
                "3. Merge cleaned string variables – if applicable"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>designation</th>\n",
                            "      <th>description</th>\n",
                            "      <th>imageid</th>\n",
                            "      <th>prdtypecode</th>\n",
                            "      <th>designation_cleaned</th>\n",
                            "      <th>description_cleaned</th>\n",
                            "      <th>designation_len</th>\n",
                            "      <th>description_len</th>\n",
                            "      <th>designation_cleaned_len</th>\n",
                            "      <th>description_cleaned_len</th>\n",
                            "      <th>...</th>\n",
                            "      <th>description_separator</th>\n",
                            "      <th>description_parentheses</th>\n",
                            "      <th>description_question_marks</th>\n",
                            "      <th>description_question_mark_char_count</th>\n",
                            "      <th>description_hyphens</th>\n",
                            "      <th>designation_empty</th>\n",
                            "      <th>description_empty</th>\n",
                            "      <th>identical_original</th>\n",
                            "      <th>identical_cleaned</th>\n",
                            "      <th>text_merged</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>productid</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>3804725264</th>\n",
                            "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
                            "      <td>None</td>\n",
                            "      <td>1263597046</td>\n",
                            "      <td>10</td>\n",
                            "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
                            "      <td></td>\n",
                            "      <td>88</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>88</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>436067568</th>\n",
                            "      <td>Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...</td>\n",
                            "      <td>None</td>\n",
                            "      <td>1008141237</td>\n",
                            "      <td>2280</td>\n",
                            "      <td>Journal Des Arts Le N° 133 Du 28/09/2001 - L'a...</td>\n",
                            "      <td></td>\n",
                            "      <td>206</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>204</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Journal Des Arts Le N° 133 Du 28/09/2001 - L'a...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>201115110</th>\n",
                            "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
                            "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
                            "      <td>938777978</td>\n",
                            "      <td>50</td>\n",
                            "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
                            "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
                            "      <td>76</td>\n",
                            "      <td>760.0</td>\n",
                            "      <td>76</td>\n",
                            "      <td>674</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>50418756</th>\n",
                            "      <td>Peluche Donald - Europe - Disneyland 2000 (Mar...</td>\n",
                            "      <td>None</td>\n",
                            "      <td>457047496</td>\n",
                            "      <td>1280</td>\n",
                            "      <td>Peluche Donald - Europe - Disneyland 2000 Mari...</td>\n",
                            "      <td></td>\n",
                            "      <td>63</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>61</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Peluche Donald - Europe - Disneyland 2000 Mari...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>278535884</th>\n",
                            "      <td>La Guerre Des Tuques</td>\n",
                            "      <td>Luc a des id&amp;eacute;es de grandeur. Il veut or...</td>\n",
                            "      <td>1077757786</td>\n",
                            "      <td>2705</td>\n",
                            "      <td>La Guerre Des Tuques</td>\n",
                            "      <td>Luc a des idées de grandeur. Il veut organiser...</td>\n",
                            "      <td>20</td>\n",
                            "      <td>213.0</td>\n",
                            "      <td>20</td>\n",
                            "      <td>187</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>La Guerre Des Tuques - Luc a des idées de gran...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 53 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                  designation  \\\n",
                            "productid                                                       \n",
                            "3804725264  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
                            "436067568   Journal Des Arts (Le) N° 133 Du 28/09/2001 - L...   \n",
                            "201115110   Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
                            "50418756    Peluche Donald - Europe - Disneyland 2000 (Mar...   \n",
                            "278535884                                La Guerre Des Tuques   \n",
                            "\n",
                            "                                                  description     imageid  \\\n",
                            "productid                                                                   \n",
                            "3804725264                                               None  1263597046   \n",
                            "436067568                                                None  1008141237   \n",
                            "201115110   PILOT STYLE Touch Pen de marque Speedlink est ...   938777978   \n",
                            "50418756                                                 None   457047496   \n",
                            "278535884   Luc a des id&eacute;es de grandeur. Il veut or...  1077757786   \n",
                            "\n",
                            "            prdtypecode                                designation_cleaned  \\\n",
                            "productid                                                                    \n",
                            "3804725264           10  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
                            "436067568          2280  Journal Des Arts Le N° 133 Du 28/09/2001 - L'a...   \n",
                            "201115110            50  Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
                            "50418756           1280  Peluche Donald - Europe - Disneyland 2000 Mari...   \n",
                            "278535884          2705                               La Guerre Des Tuques   \n",
                            "\n",
                            "                                          description_cleaned  \\\n",
                            "productid                                                       \n",
                            "3804725264                                                      \n",
                            "436067568                                                       \n",
                            "201115110   PILOT STYLE Touch Pen de marque Speedlink est ...   \n",
                            "50418756                                                        \n",
                            "278535884   Luc a des idées de grandeur. Il veut organiser...   \n",
                            "\n",
                            "            designation_len  description_len  designation_cleaned_len  \\\n",
                            "productid                                                               \n",
                            "3804725264               88              NaN                       88   \n",
                            "436067568               206              NaN                      204   \n",
                            "201115110                76            760.0                       76   \n",
                            "50418756                 63              NaN                       61   \n",
                            "278535884                20            213.0                       20   \n",
                            "\n",
                            "            description_cleaned_len  ...  description_separator  \\\n",
                            "productid                            ...                          \n",
                            "3804725264                        0  ...                      0   \n",
                            "436067568                         0  ...                      0   \n",
                            "201115110                       674  ...                      0   \n",
                            "50418756                          0  ...                      0   \n",
                            "278535884                       187  ...                      0   \n",
                            "\n",
                            "            description_parentheses  description_question_marks  \\\n",
                            "productid                                                         \n",
                            "3804725264                        0                           0   \n",
                            "436067568                         0                           0   \n",
                            "201115110                         0                           0   \n",
                            "50418756                          0                           0   \n",
                            "278535884                         0                           0   \n",
                            "\n",
                            "            description_question_mark_char_count  description_hyphens  \\\n",
                            "productid                                                               \n",
                            "3804725264                                     0                    0   \n",
                            "436067568                                      0                    0   \n",
                            "201115110                                      0                    0   \n",
                            "50418756                                       0                    0   \n",
                            "278535884                                      0                    0   \n",
                            "\n",
                            "            designation_empty  description_empty  identical_original  \\\n",
                            "productid                                                              \n",
                            "3804725264                  0                  0                   0   \n",
                            "436067568                   0                  0                   0   \n",
                            "201115110                   0                  0                   0   \n",
                            "50418756                    0                  0                   0   \n",
                            "278535884                   0                  0                   0   \n",
                            "\n",
                            "            identical_cleaned  \\\n",
                            "productid                       \n",
                            "3804725264                  0   \n",
                            "436067568                   0   \n",
                            "201115110                   0   \n",
                            "50418756                    0   \n",
                            "278535884                   0   \n",
                            "\n",
                            "                                                  text_merged  \n",
                            "productid                                                      \n",
                            "3804725264  Olivia: Personalisiertes Notizbuch / 150 Seite...  \n",
                            "436067568   Journal Des Arts Le N° 133 Du 28/09/2001 - L'a...  \n",
                            "201115110   Grand Stylet Ergonomique Bleu Gamepad Nintendo...  \n",
                            "50418756    Peluche Donald - Europe - Disneyland 2000 Mari...  \n",
                            "278535884   La Guerre Des Tuques - Luc a des idées de gran...  \n",
                            "\n",
                            "[5 rows x 53 columns]"
                        ]
                    },
                    "execution_count": 72,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#df_text_train_merge = text_merger(df_text_train_clean) # Duration 10may2025: 7s\n",
                "\n",
                "#df_text_train_merge.to_parquet('df_text_train_merge.parquet', index=True)\n",
                "#df_text_train_merge.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Comparison** of content in columns containing text data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>text_merged</th>\n",
                            "      <th>designation_cleaned</th>\n",
                            "      <th>description_cleaned</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>productid</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>3804725264</th>\n",
                            "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
                            "      <td>Olivia: Personalisiertes Notizbuch / 150 Seite...</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>436067568</th>\n",
                            "      <td>Journal Des Arts Le N° 133 Du 28/09/2001 - L'a...</td>\n",
                            "      <td>Journal Des Arts Le N° 133 Du 28/09/2001 - L'a...</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>201115110</th>\n",
                            "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
                            "      <td>Grand Stylet Ergonomique Bleu Gamepad Nintendo...</td>\n",
                            "      <td>PILOT STYLE Touch Pen de marque Speedlink est ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>50418756</th>\n",
                            "      <td>Peluche Donald - Europe - Disneyland 2000 Mari...</td>\n",
                            "      <td>Peluche Donald - Europe - Disneyland 2000 Mari...</td>\n",
                            "      <td></td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>278535884</th>\n",
                            "      <td>La Guerre Des Tuques - Luc a des idées de gran...</td>\n",
                            "      <td>La Guerre Des Tuques</td>\n",
                            "      <td>Luc a des idées de grandeur. Il veut organiser...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                  text_merged  \\\n",
                            "productid                                                       \n",
                            "3804725264  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
                            "436067568   Journal Des Arts Le N° 133 Du 28/09/2001 - L'a...   \n",
                            "201115110   Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
                            "50418756    Peluche Donald - Europe - Disneyland 2000 Mari...   \n",
                            "278535884   La Guerre Des Tuques - Luc a des idées de gran...   \n",
                            "\n",
                            "                                          designation_cleaned  \\\n",
                            "productid                                                       \n",
                            "3804725264  Olivia: Personalisiertes Notizbuch / 150 Seite...   \n",
                            "436067568   Journal Des Arts Le N° 133 Du 28/09/2001 - L'a...   \n",
                            "201115110   Grand Stylet Ergonomique Bleu Gamepad Nintendo...   \n",
                            "50418756    Peluche Donald - Europe - Disneyland 2000 Mari...   \n",
                            "278535884                                La Guerre Des Tuques   \n",
                            "\n",
                            "                                          description_cleaned  \n",
                            "productid                                                      \n",
                            "3804725264                                                     \n",
                            "436067568                                                      \n",
                            "201115110   PILOT STYLE Touch Pen de marque Speedlink est ...  \n",
                            "50418756                                                       \n",
                            "278535884   Luc a des idées de grandeur. Il veut organiser...  "
                        ]
                    },
                    "execution_count": 75,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_text_train_merge = pd.read_parquet('df_text_train_merge.parquet')\n",
                "df_text_train_merge = df_text_train_merge[['text_merged', 'designation_cleaned', 'description_cleaned']]\n",
                "df_text_train_merge.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exploration of image data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preprocessing // Load DataFrame with image data\n",
                "`Note:` The repository contains an updated and preprocessed version of df_image_train.csv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_image_train = pd.read_csv(\"df_image_train.csv\", index_col=\"productid\")\n",
                "#df_image_train.head()\n",
                "\n",
                "df_image_test = pd.read_csv(\"X_test.csv\", index_col=\"productid\", usecols=[\"productid\", \"imageid\"])\n",
                "#df_image_test.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Preprocessing // Images**\n",
                "\n",
                "`NOTE:` Running the following cell to extract data from all image files and save it to df_image_train.csv is **only necessary after** an update of the module image_utils.py. Otherwise you can proceed with the import in the next code cell of you interest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#df_image_train = image_data_extractor(df_image_train)  # Command takes a while to run: ~ 1 hour\n",
                "#df_image_train.to_csv('df_image_train.csv', index=False)\n",
                "#df_image_train.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#df_image_test = image_data_extractor(df_image_test, base_path=\"./images/image_test/\") # Duration 25apr2025: 1min 18s\n",
                "#df_image_test.to_csv('df_image_test.csv', index=False)\n",
                "#df_image_test.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Import image data**\n",
                "1. File information, e.g.\n",
                "    1. productid\n",
                "    2. imageid\n",
                "2. Size information\n",
                "    1. width, height, ...\n",
                "    2. aspect_ratio\n",
                "3. EXIF and meta data\n",
                "    1. meta_jfif, ... meta_progressive, ...\n",
                "    2. mean_r, mean_g, mean_b, mean_brightness, ... "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** How many aspect ratios are in the DataFrame?\n",
                "\n",
                "**Answer:** All product images have an aspect ratio of 1:1 with a resolution of 500 × 500 px\n",
                "\n",
                "Relates to [Issue #45 Step 2 // Preprocessing: Image Processing](https://github.com/PeterStieg/feb25_bds_classification-of-rakuten-e-commerce-products/issues/45)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# pt_img_ar as in \"Pivot Table for Images' Aspect Ratio\"\n",
                "pt_img_ar = pd.pivot_table(df_image_train[['aspect_ratio', 'width', 'height']],\n",
                "                           index='aspect_ratio',\n",
                "                           aggfunc={'aspect_ratio': 'count', 'height': 'mean', 'width': 'mean'})\n",
                "\n",
                "pt_img_ar = pt_img_ar.rename(columns={'aspect_ratio': 'count'})\n",
                "\n",
                "pt_img_ar"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preprocessing // Images: Detect bounding boxes\n",
                "\n",
                "Relates to Issue [Issue #62 Step 2 // Preprocessing: Object localization via bounding boxes in images](https://github.com/PeterStieg/feb25_bds_classification-of-rakuten-e-commerce-products/issues/62)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#df_image_train = detect_bounding_box_parallel(df_image_train) # Duration 22apr2025: 6min\n",
                "#df_image_train.to_csv(\"df_image_train.csv\", index=True)\n",
                "#df_image_train.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#df_image_test = detect_bounding_box_parallel(df_image_test, base_path=\"./images/image_test/\") # Duration 25apr2025: 46sec\n",
                "#df_image_test.to_csv(\"df_image_test.csv\", index=True)\n",
                "#df_image_test.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preprocessing // Images: Crop and resize to target size\n",
                "\n",
                "Relates to Issue [Issue #63 Step 2 // Preprocessing: Crop and resize image](https://github.com/PeterStieg/feb25_bds_classification-of-rakuten-e-commerce-products/issues/63)\n",
                "1. Crop and resize images contained in a DataFrame according to bounding box dimensions\n",
                "2. Add columns 'downscaled', 'upscaled' and 'exclude' to DataFrame df_image_train(.csv)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#df_image_train = pd.read_csv(\"df_image_train.csv\", index_col=\"productid\")\n",
                "#df_image_train = crop_pad_and_resize_image_parallel(df_image_train) # Duration 22apr2025: 6min 34s\n",
                "#df_image_train.to_csv(\"df_image_train.csv\")\n",
                "#df_image_train.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#df_image_test = pd.read_csv(\"df_image_test.csv\", index_col=\"productid\")\n",
                "#df_image_test = crop_pad_and_resize_image_parallel(df_image_test, base_path=\"./images/image_test/\") # Duration 25apr2025: 1min 30s\n",
                "#df_image_test.to_csv(\"df_image_test.csv\")\n",
                "#df_image_test.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preprocessing // Images: Find duplicates with perceptual hashing\n",
                "\n",
                "Relates to Issue [Issue #67 Step 2 // Preprocessing: Find duplicates with perceptual hashing](https://github.com/PeterStieg/feb25_bds_classification-of-rakuten-e-commerce-products/issues/67)\n",
                "1. Compute perceptual hash\n",
                "2. Add columns 'phash' to DataFrame df_image_train(.csv)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#df_image_train = pd.read_csv(\"df_image_train.csv\", index_col=\"productid\")\n",
                "#df_image_train = hash_parallel(df_image_train) # Duration 22apr2025: 5min 14s\n",
                "#df_image_train.to_csv(\"df_image_train.csv\")\n",
                "#df_image_train.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#df_image_train = pd.read_csv(\"df_image_train.csv\", index_col=\"productid\")\n",
                "\n",
                "#df_image_train, unique_duplicates = find_duplicates_parallel(df_image_train, threshold=0) # Duration 23apr2025: 42min\n",
                "#df_image_train.to_csv(f\"df_image_train.csv\")\n",
                "\n",
                "# Create a DataFrame from the duplicate pairs\n",
                "#df_image_duplicates = create_duplicates_dataframe(unique_duplicates)\n",
                "#df_image_duplicates.to_csv(f\"df_image_duplicates.csv\", index=False)\n",
                "#df_image_duplicates.head()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exploration of target data (product type code)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** What does the target data look like?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Display basic **information** about the target data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(y_train.info())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** Are there any missing values (NaN)?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"The attribute \\033[1m'product type code'\\033[0m has no missing data:\")\n",
                "\n",
                "y_train.isna().any()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** How many different product type codes are there?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prdtypecode_list = sorted(set(y_train['prdtypecode']))\n",
                "prdtypecode_len = len(prdtypecode_list)\n",
                "\n",
                "print(f\"List containing all \\033[1m{prdtypecode_len} product type codes\\033[0m:\")\n",
                "print(prdtypecode_list, end='\\n\\n')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Assigning Product Type Codes to Categories**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a dictionary for French category names:\n",
                "# Product type code -> Product Category, French\n",
                "prdtypecode_dict_FR = {   \n",
                "    10: 'Livres > ??More than 1 Sub-Category??',\n",
                "    2280: 'Livres > Revue',\n",
                "    2705: 'Livres > eBooks',\n",
                "    2522: 'Livres > Fournitures Papeterie',\n",
                "    2403: 'Livres > Lots de Livres et de Revues',\n",
                "\n",
                "    50: 'Jeux vidéo & Consoles > Accessoires Jeux Vidéo',\n",
                "    1140: 'Jeux vidéo & Consoles > Figurines',\n",
                "    1180: 'Jeux vidéo & Consoles > Jeux de rôle et jeux de figurines',\n",
                "    2462: 'Jeux vidéo & Consoles > Lots de consoles et jeux vidéo',\n",
                "    1160: 'Jeux vidéo & Consoles Cartes de jeux',\n",
                "    40: 'Jeux vidéo & Consoles > Jeux Vidéo',\n",
                "    60: 'Jeux vidéo & Consoles > Consoles',\n",
                "    2905: 'Jeux vidéo & Consoles > Jeux Vidéo > Jeux vidéo PC', #3. Ebene! Unterkategorie von 60\n",
                "    \n",
                "    1280: 'Jouets > Enfant Jouets',\n",
                "    1300: 'Jouets & Enfant > Modélisme',\n",
                "    1320: 'Jouets & Enfant > Puériculture',\n",
                "    1302: 'Jouets & Enfant Jeux de plein air',\n",
                "    1301: 'Jouets & Enfant > Jeux de café',\n",
                "    1281: 'Jouets & Enfant > Jeux de société ',\n",
                "    \n",
                "    2582: 'Jardin & Piscine > Mobilier de jardin',\n",
                "    2583: 'Jardin & Piscine > Entretien piscine & spa',\n",
                "    2585: 'Jardin & Piscine > Outillage de jardin',\n",
                "\n",
                "    1560: 'Maison > Mobilier ',\n",
                "    1920: '??Maison > 1640 Linge de Maison ??',#nochmal checken\n",
                "    2060: '??Maison > decoration??', #nochmal checken\n",
                "\n",
                "    1940: 'Vins et Gastronomie > Petit déjeuner',\n",
                "\n",
                "    2220: 'Animalerie > Accessoires et nourriture pour chien'\n",
                "    }\n",
                "\n",
                "                          \n",
                "# Map the French dictionary to prdtypecode column\n",
                "df_text_train['prod_cat_fr'] = df_text_train['prdtypecode'].map(prdtypecode_dict_FR)                          \n",
                "                                            \n",
                "\n",
                "# Define a dictionary for English category names:\n",
                "# Product type code -> Product Category, English\n",
                "# Peter 31mar2025: We could simplify the code by using a single dictionary for both French and English categories.\n",
                "prdtypecode_dict_EN = {\n",
                "    10: 'Books > ??More than 1 Sub-Category??',\n",
                "    2280: 'Books > Magazine',\n",
                "    2705: 'Books > eBooks',\n",
                "    2522: 'Books > Stationery Supplies',\n",
                "    2403: 'Books > Batches of Books and Magazines',\n",
                "\n",
                "    50: 'Video Games & Consoles > Video Game Accessories',\n",
                "    1140: 'Video Games & Consoles > Figures',\n",
                "    1180: 'Video Games & Consoles > Role-playing games and miniature games',\n",
                "    2462: 'Video Games & Consoles > Batches of consoles and video games',\n",
                "    1160: 'Video Games & Consoles Game cards',\n",
                "    40: 'Video Games & Consoles > Video Games',\n",
                "    60: 'Video Games & Consoles > Consoles',\n",
                "    2905: 'Video Games & Consoles > Video Games > PC video games', #3. Ebene! Unterkategorie von 60\n",
                "    \n",
                "    1280: 'Toys & Children > Toys',\n",
                "    1300: 'Toys & Children > Model making',\n",
                "    1320: 'Toys & Children > Childcare',\n",
                "    1302: 'Toys & Children > Outdoor games',\n",
                "    1301: 'Toys & Children > Cafe games',\n",
                "    1281: 'Toys & Children > Board games',\n",
                "    \n",
                "    2582: 'Garden & Pool > Garden furniture',\n",
                "    2583: 'Garden & Pool > Pool & spa maintenance',\n",
                "    2585: 'Garden & Pool > Garden tools',\n",
                "\n",
                "    1560: 'Home > Furniture',\n",
                "    1920: '??Home > 1640 Household Linens??',#nochmal checken\n",
                "    2060: '??Home > decoration??', #nochmal checken\n",
                "\n",
                "    1940: 'Wines and Gastronomy > Breakfast',\n",
                "\n",
                "    2220: 'Pet Store > Dog Accessories and Food'\n",
                "    }\n",
                "\n",
                "# Map the English dictionary to prdtypecode column\n",
                "df_text_train['prod_cat_en'] = df_text_train['prdtypecode'].map(prdtypecode_dict_EN)                          \n",
                "\n",
                "\n",
                "\"\"\"\n",
                "Category / Subcategory?\n",
                "Issues:\n",
                "\n",
                "1. Category 10 seems to belong to more than one subcategory of books, yet it is not the parent category of the other subcategories. (100)\n",
                "2. Category 60 seems to be the parent category of 2905.\n",
                "3. I can not confirm Categories 1920 & 2060. I could not find them in the html/css code of the website.\n",
                "\n",
                "Suggestions:\n",
                "1. ?\n",
                "2. Change Category 2950 to 60 for consistency. Check for duplicates in category 60.\n",
                "3. ?\n",
                "\n",
                "\"\"\"\n",
                "\n",
                "# Display DataFrame 'df_text_train' to verify\n",
                "display(df_text_train.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Assigning Parent Categories**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a dictionary for parent categories in French\n",
                "parent_category_dict_fr = {\n",
                "    10: 'Livres',\n",
                "    2280: 'Livres',\n",
                "    2705: 'Livres',\n",
                "    2522: 'Livres',\n",
                "    2403: 'Livres',\n",
                "    50: 'Jeux vidéo et consoles',\n",
                "    1140: 'Jeux vidéo et consoles',\n",
                "    1180: 'Jeux vidéo et consoles',\n",
                "    2462: 'Jeux vidéo et consoles',\n",
                "    1160: 'Jeux vidéo et consoles',\n",
                "    40: 'Jeux vidéo et consoles',\n",
                "    60: 'Jeux vidéo et consoles',\n",
                "    2905: 'Jeux vidéo et consoles',  # Parent category of 2905 is 60\n",
                "    1280: 'Jouets et enfants',\n",
                "    1300: 'Jouets et enfants',\n",
                "    1320: 'Jouets et enfants',\n",
                "    1302: 'Jouets et enfants',\n",
                "    1301: 'Jouets et enfants',\n",
                "    1281: 'Jouets et enfants',\n",
                "    2582: 'Jardin et piscine',\n",
                "    2583: 'Jardin et piscine',\n",
                "    2585: 'Jardin et piscine',\n",
                "    1560: 'Maison',\n",
                "    1920: 'Maison',\n",
                "    2060: 'Maison',\n",
                "    1940: 'Vins et gastronomie',\n",
                "    2220: 'Animalerie'\n",
                "    }\n",
                "\n",
                "# Map the parent category to a new column using the French dictionary\n",
                "df_text_train['parent_category_fr'] = df_text_train['prdtypecode'].map(parent_category_dict_fr)\n",
                "\n",
                "\n",
                "# Define a dictionary for English parent categories\n",
                "# Peter 31mar2025: We could simplify the code by using a single dictionary for both French and English categories.\n",
                "parent_category_dict_en = {\n",
                "    10: 'Books',\n",
                "    2280: 'Books',\n",
                "    2705: 'Books',\n",
                "    2522: 'Books',\n",
                "    2403: 'Books',\n",
                "    50: 'Video Games & Consoles',\n",
                "    1140: 'Video Games & Consoles',\n",
                "    1180: 'Video Games & Consoles',\n",
                "    2462: 'Video Games & Consoles',\n",
                "    1160: 'Video Games & Consoles',\n",
                "    40: 'Video Games & Consoles',\n",
                "    60: 'Video Games & Consoles',\n",
                "    2905: 'Video Games & Consoles',  # Parent category of 2905 is 60\n",
                "    1280: 'Toys & Children',\n",
                "    1300: 'Toys & Children',\n",
                "    1320: 'Toys & Children',\n",
                "    1302: 'Toys & Children',\n",
                "    1301: 'Toys & Children',\n",
                "    1281: 'Toys & Children',\n",
                "    2582: 'Garden & Pool',\n",
                "    2583: 'Garden & Pool',\n",
                "    2585: 'Garden & Pool',\n",
                "    1560: 'Home',\n",
                "    1920: 'Home',\n",
                "    2060: 'Home',\n",
                "    1940: 'Wines and Gastronomy',\n",
                "    2220: 'Pet Store'\n",
                "    }\n",
                "\n",
                "\n",
                "# Map the parent category to a new column using the English dictionary\n",
                "df_text_train['parent_category_en'] = df_text_train['prdtypecode'].map(parent_category_dict_en)\n",
                "\n",
                "\n",
                "# Display DataFrame 'df_text_train' to verify\n",
                "display(df_text_train.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Text Normalization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"\n",
                "IMPORTANT NOTES:\n",
                "\n",
                "Text normalization has been put into backlog of our project. Since I have already started working on this process, I did not want to loose progress. \n",
                "All the following steps are just a first sketch of the process.\n",
                "\n",
                "\n",
                "- In the described process: Stemming or lemmatization is not included because contextual embeddings (CamemBERT) already handle word variations and synonyms effectively.\n",
                "- synonym mapping, regular expressions, and tokenization are largely redundant when using contextual embeddings like CamemBERT.\n",
                "- Stopword removal is optional when using contextual embeddings like CamemBERT, as they can handle common words effectively.\n",
                "\n",
                "\n",
                "If we want to apply the following we must save it for the test data, \n",
                "to be processed in the same way as the training data. Can this be handled in the pipeline?\n",
                "\"\"\"\n",
                "\n",
                "#ALL CODE IN TRIPPLE QUOTES TO NOT EXECUTE IT\n",
                "\n",
                "\"\"\"\n",
                "# 1. Lowercasing and Remove Accents\n",
                "#Normalize the text by lowercasing and removing accents. This step ensures consistency.\n",
                "\n",
                "import unicodedata \n",
                "# Peter 31mar2025: I could/would use this module in the function text_cleaner() during text cleaning\n",
                "\n",
                "def normalize_text(text):\n",
                "    # Lowercase\n",
                "    text = text.lower()\n",
                "    # Remove accents\n",
                "    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
                "    return text\n",
                "\n",
                "# Apply normalization to both columns\n",
                "df_text_train['designation'] = df_text_train['designation'].apply(normalize_text)\n",
                "df_text_train['description'] = df_text_train['description'].apply(normalize_text)\n",
                "\n",
                "# 2. Generating Contextual Embeddings\n",
                "#Using CamemBERT to generate embeddings for each row in the title and description columns. \n",
                "#This step captures the semantic meaning of the text.\n",
                "\n",
                "from transformers import CamembertTokenizer, CamembertModel \n",
                "# Peter 31mar2025: I would move all imports to the setup section of the notebook\n",
                "\n",
                "# Load the tokenizer and model\n",
                "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
                "model = CamembertModel.from_pretrained(\"camembert-base\")\n",
                "\n",
                "import torch\n",
                "\n",
                "def get_embedding(text):\n",
                "    # Tokenize the input text\n",
                "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
                "    # Pass the input through the model\n",
                "    outputs = model(**inputs)\n",
                "    # Extract the embeddings (mean of the last hidden state)\n",
                "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
                "\n",
                "# Generate embeddings for titles and descriptions\n",
                "df_text_train['designation_embedding'] = df_text_train['designation'].apply(get_embedding)\n",
                "df_text_train['description_embedding'] = df_text_train['description'].apply(get_embedding)\n",
                "\n",
                "# 3. Automatically Cluster Similar Rows\n",
                "#Instead of manually defining synonyms or rules, using unsupervised clustering to group similar rows based on their embeddings.\n",
                "import numpy as np\n",
                "\n",
                "# Combining title and description embeddings\n",
                "# Combining the designation_embedding and description_embedding into a single vector for each row.\n",
                "df_text_train['combined_embedding'] = df_text_train.apply(\n",
                "    lambda row: np.mean([row['designation_embedding'], row['description_embedding']], axis=0),\n",
                "    axis=1\n",
                ")\n",
                "# Cluster Rows\n",
                "#Using K-Means clustering to group similar rows based on their combined embeddings.\n",
                "\n",
                "from sklearn.cluster import KMeans\n",
                "\n",
                "# Stack all embeddings into a matrix\n",
                "embedding_matrix = np.vstack(df_text_train['combined_embedding'])\n",
                "\n",
                "# Cluster embeddings into groups\n",
                "num_clusters = 5  # Adjust based on your dataset\n",
                "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
                "df_text_train['cluster'] = kmeans.fit_predict(embedding_matrix)\n",
                "\n",
                "# 4. Replace Text with Cluster Representatives\n",
                "# Automatically replace the text in each cluster with a representative phrase \n",
                "# (e.g., the most frequent phrase in the cluster).\n",
                "\n",
                "# Find Cluster Representatives\n",
                "# Find the most common title or description in each cluster.\n",
                "\n",
                "# Find the representative title for each cluster\n",
                "cluster_representatives = df_text_train.groupby('cluster')['designation'].agg(lambda x: x.value_counts().idxmax()).to_dict()\n",
                "\n",
                "# Replace titles and descriptions with their cluster representative\n",
                "df_text_train['normalized_designation'] = df_text_train['cluster'].map(cluster_representatives)\n",
                "df_text_train['normalized_description'] = df_text_train['cluster'].map(cluster_representatives)\n",
                "\n",
                "# 5. Save the Normalized Data\n",
                "# Save the normalized DataFrame for further use.\n",
                "\n",
                "\n",
                "df_text_train.to_csv(\"normalized_products.csv\", index=False)\"\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "long_titles = df_text_train[df_text_train['designation'].str.len()>=240]\n",
                "print(long_titles['designation'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**1. Distribution of Product Type Codes**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get value counts and sort them\n",
                "sorted_value_counts = df_text_train['prod_cat_en'].value_counts().sort_values(ascending=False)\n",
                "category_order = sorted_value_counts.index.tolist()\n",
                "\n",
                "\n",
                "# Abbreviate category names\n",
                "abbreviated_labels = [label[:15] + '...' if len(label) > 10 else label for label in category_order]\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.countplot(x='prod_cat_en', data=df_text_train, order=category_order)\n",
                "\n",
                "plt.xticks(ticks=range(len(category_order)), labels=abbreviated_labels, rotation=90)\n",
                "plt.title('Number of Items per Category')\n",
                "plt.xlabel('Product Categories')\n",
                "plt.ylabel('Count')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here we have two different versions of the same plot. I find the matplotlib one visually more pleasing plus it is sorted, which makes it easier to interpret."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "product_type_counts = y_train['prdtypecode'].value_counts()\n",
                "\n",
                "# Plot the distribution\n",
                "plt.figure(figsize=(10, 6))\n",
                "product_type_counts.plot(kind='bar', color='skyblue')\n",
                "plt.title('Distribution of Product Type Codes', fontsize=16)\n",
                "plt.xlabel('Product Type Code', fontsize=14)\n",
                "plt.ylabel('Count', fontsize=14)\n",
                "plt.xticks(rotation=45, fontsize=12)\n",
                "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
                "plt.tight_layout()\n",
                "\n",
                "# Show the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As we can see the product type codes are not equally distibuted. The code 2583 is by far the most represented code with >10k counts. Approximately a third of the rest of the codes have around 4-5k counts, followed by another third with around 3k counts, and the last third with around 1k count each."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The exact percentages of each codes value count is displayed in the following pie chart."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(figsize=(8, 8))\n",
                "wedges, texts, autotexts = ax.pie(\n",
                "    product_type_counts,\n",
                "    autopct='%1.1f%%',  # Display percentages\n",
                "    startangle=90,\n",
                "    colors=plt.cm.tab20.colors,  # Use colormap\n",
                "    textprops={'fontsize': 10},  # Adjust font size for better readability\n",
                "    pctdistance=1.1  # Move percentages outside the pie\n",
                ")\n",
                "\n",
                "# Add a legend outside the pie chart\n",
                "ax.legend(\n",
                "    wedges,\n",
                "    product_type_counts.index,  # Labels for the legend\n",
                "    title=\"Product Type Codes\",\n",
                "    loc=\"center left\",\n",
                "    bbox_to_anchor=(1, 0, 0.5, 1),  # Position legend outside the chart\n",
                "    fontsize=10\n",
                ")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here we have the distribution on parent category level:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the distribution of English parent categories\n",
                "category_distribution = df_text_train['parent_category_en'].value_counts()\n",
                "\n",
                "# Plot the distribution as a bar chart\n",
                "plt.figure(figsize=(10, 6))\n",
                "category_distribution.plot(kind='bar', color='skyblue')\n",
                "plt.title('Distribution of English Parent Categories', fontsize=16)\n",
                "plt.xlabel('Parent Category', fontsize=14)\n",
                "plt.ylabel('Count', fontsize=14)\n",
                "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**2. Distributions of items without descriptions**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Maybe we can also sort this, and use the same style graph as above for unified look."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate counts for the filtered DataFrame and sort them in descending order\n",
                "sorted_value_counts = df_text_train[df_text_train.isnull().any(axis=1)]['prod_cat_en'].value_counts().sort_values(ascending=False)\n",
                "category_order = sorted_value_counts.index.tolist()\n",
                "\n",
                "# Abbreviate category names\n",
                "abbreviated_labels = [label[:15] + '...' if len(label) > 15 else label for label in category_order]\n",
                "\n",
                "# Create the countplot\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.countplot(x='prod_cat_en', data=df_text_train[df_text_train.isnull().any(axis=1)], order=category_order)\n",
                "\n",
                "# Apply abbreviated labels and rotate them\n",
                "plt.xticks(ticks=range(len(category_order)), labels=abbreviated_labels, rotation=90)\n",
                "plt.title('Countplot of items without descriptions')\n",
                "plt.xlabel('Product Categories')\n",
                "plt.ylabel('Count')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Interpretation?/Observations?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The same graph but on parent category level:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter the DataFrame for rows with missing descriptions\n",
                "missing_description_df = df_text_train[df_text_train.isnull().any(axis=1)]\n",
                "\n",
                "# Plot the count of English parent categories with missing descriptions\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.countplot(x='parent_category_en', data=missing_description_df, palette='viridis')\n",
                "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
                "plt.title('Countplot of Items Without Descriptions by Parent Category', fontsize=16)\n",
                "plt.xlabel('English Parent Categories', fontsize=14)\n",
                "plt.ylabel('Count', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**3. Distribution of items with description**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Maybe use one style and order descending?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate counts for the filtered DataFrame (rows with descriptions) and sort them in descending order\n",
                "sorted_value_counts_with_desc = df_text_train[df_text_train.notnull().all(axis=1)]['prod_cat_en'].value_counts().sort_values(ascending=False)\n",
                "category_order_with_desc = sorted_value_counts_with_desc.index.tolist()\n",
                "\n",
                "# Abbreviate category names\n",
                "abbreviated_labels_with_desc = [label[:15] + '...' if len(label) > 15 else label for label in category_order_with_desc]\n",
                "\n",
                "# Create the countplot\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.countplot(x='prod_cat_en', data=df_text_train[df_text_train.notnull().all(axis=1)], order=category_order_with_desc)\n",
                "\n",
                "# Apply abbreviated labels and rotate them\n",
                "plt.xticks(ticks=range(len(category_order_with_desc)), labels=abbreviated_labels_with_desc, rotation=90)\n",
                "plt.title('Countplot of items with descriptions')\n",
                "plt.xlabel('Product Categories')\n",
                "plt.ylabel('Count')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Interpretation?/Observations?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The same on parent category level:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter the DataFrame for rows with descriptions (no missing values)\n",
                "with_description_df = df_text_train[df_text_train.notnull().all(axis=1)]\n",
                "\n",
                "# Plot the count of English parent categories with descriptions\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.countplot(x='parent_category_en', data=with_description_df, palette='viridis')\n",
                "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
                "plt.title('Countplot of Items With Descriptions by Parent Category', fontsize=16)\n",
                "plt.xlabel('English Parent Categories', fontsize=14)\n",
                "plt.ylabel('Count', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**4. Relative distribution of product descriptions**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate total counts and counts with descriptions for each parent category\n",
                "total_counts = df_text_train['parent_category_en'].value_counts()\n",
                "with_description_counts = df_text_train[df_text_train.notnull().all(axis=1)]['parent_category_en'].value_counts()\n",
                "\n",
                "# Calculate the percentage of items with descriptions\n",
                "description_percentage = (with_description_counts / total_counts) * 100\n",
                "\n",
                "# Plot the percentage of items with descriptions\n",
                "plt.figure(figsize=(12, 6))\n",
                "description_percentage.sort_values(ascending=False).plot(kind='bar', color='skyblue')\n",
                "plt.title('Percentage of Items With Descriptions by Parent Category', fontsize=16)\n",
                "plt.xlabel('English Parent Categories', fontsize=14)\n",
                "plt.ylabel('Percentage (%)', fontsize=14)\n",
                "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**4. Distribution of Title Lengths**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the length of each product title\n",
                "df_text_train['title_length'] = df_text_train['designation'].str.len()\n",
                "\n",
                "# Plot the histogram\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.histplot(\n",
                "    data=df_text_train,\n",
                "    x='title_length',\n",
                "    bins=25,  # Number of bins for the histogram\n",
                "    kde=True,  # Add a kernel density estimate (smooth curve)\n",
                "    color='skyblue'\n",
                ")\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Distribution of Product Title Lengths', fontsize=16)\n",
                "plt.xlabel('Title Length (Number of Characters)', fontsize=14)\n",
                "plt.ylabel('Frequency', fontsize=14)\n",
                "plt.tight_layout()\n",
                "\n",
                "# Show the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The title lengths follow a somewhat normal and bimodal distributed, but there is a heavy scew to the left, with a bit of a tail to right, getting very thin above 150 characters. Interestingly there is a small spike at around 250 characters. This peak might be due to a maximum allowed length, which also explains why there are no extreme outliers. The rest of the data is distributed around the largest peak in the 40 - 50 character range, and another smaller peak at 80 - 90 characters."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**5. Distribution of description length**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "5.1 Histogram of Product Description Lengths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the length of each product title\n",
                "df_text_train['description_length'] = df_text_train['description'].str.len()\n",
                "\n",
                "# Plot the histogram\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.histplot(\n",
                "    data=df_text_train,\n",
                "    x='description_length',\n",
                "    bins=25,  # Number of bins for the histogram\n",
                "    kde=True,  # Add a kernel density estimate (smooth curve)\n",
                "    color='skyblue'\n",
                ")\n",
                "\n",
                "# Add labels and title"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We see that there is a very long tail with extremely long descriptions."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "5.2 Boxplot of Product Description lenghts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the length of each product title (if not already done)\n",
                "df_text_train['description_length'] = df_text_train['description'].str.len()\n",
                "\n",
                "# Plot the boxplot\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(\n",
                "    data=df_text_train,\n",
                "    x='description_length',\n",
                "    color='skyblue'\n",
                ")\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Boxplot of Product Description Lengths', fontsize=16)\n",
                "plt.xlabel('Description Length (Number of Characters)', fontsize=14)\n",
                "plt.tight_layout()\n",
                "\n",
                "# Show the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There are a lot of outliers with extremely long descriptions. Let's take a closer look at the outliers:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the IQR (Interquartile Range)\n",
                "Q1 = df_text_train['description_length'].quantile(0.25)  # First quartile (25th percentile)\n",
                "Q3 = df_text_train['description_length'].quantile(0.75)  # Third quartile (75th percentile)\n",
                "IQR = Q3 - Q1  # Interquartile range\n",
                "\n",
                "# Calculate the upper whisker threshold\n",
                "upper_whisker = Q3 + 1.5 * IQR\n",
                "\n",
                "# Count the number of outliers above the upper whisker\n",
                "outliers_above = df_text_train[df_text_train['description_length'] > upper_whisker]\n",
                "outlier_count = len(outliers_above)\n",
                "\n",
                "print(f\"The threshold for outliers is {upper_whisker} words in the description.\")\n",
                "print(f\"Number of outliers above the upper whisker: {outlier_count}\")\n",
                "print(f\"Percentage of outliers: {outlier_count / len(df_text_train) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Samples of Outliers:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter outliers above the upper whisker\n",
                "outliers_above = df_text_train[df_text_train['description_length'] > upper_whisker]\n",
                "\n",
                "# Display the descriptions of 5 outliers\n",
                "print(outliers_above['description'].head(5))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Some of the descriptions feature a lot of blank spaces. The first description has 160 before the text. Some, but not all outliers seem to have html code in them."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Sample of normal length descriptions:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the IQR (Interquartile Range)\n",
                "Q1 = df_text_train['description_length'].quantile(0.25)  # First quartile (25th percentile)\n",
                "Q3 = df_text_train['description_length'].quantile(0.75)  # Third quartile (75th percentile)\n",
                "IQR = Q3 - Q1  # Interquartile range\n",
                "\n",
                "# Calculate the lower and upper whisker thresholds\n",
                "lower_whisker = Q1 - 1.5 * IQR\n",
                "upper_whisker = Q3 + 1.5 * IQR\n",
                "\n",
                "# Filter descriptions within the normal range (inside the box of the boxplot)\n",
                "normal_range = df_text_train[(df_text_train['description_length'] >= lower_whisker) & (df_text_train['description_length'] <= upper_whisker)]\n",
                "\n",
                "# Display 5 descriptions from the normal range\n",
                "print(normal_range['description'].sample(5))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The normal lenth code also has a very few html snippets, but much less than the long texts."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "5.3 Distribution of descriptions without outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the length of each product title\n",
                "df_text_train['description_length'] = df_text_train['description'].str.len()\n",
                "\n",
                "# Filter the DataFrame for description lengths shorter than 2196.5\n",
                "filtered_df = df_text_train[df_text_train['description_length'] < 2196.5]\n",
                "\n",
                "# Plot the histogram\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.histplot(\n",
                "    data=filtered_df,\n",
                "    x='description_length',\n",
                "    bins=25,  # Number of bins for the histogram\n",
                "    kde=True,  # Add a kernel density estimate (smooth curve)\n",
                "    color='skyblue'\n",
                ")\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Distribution of Product Description Lengths (< 2196.5)', fontsize=16)\n",
                "plt.xlabel('Title Length (Number of Characters)', fontsize=14)\n",
                "plt.ylabel('Frequency', fontsize=14)\n",
                "plt.tight_layout()\n",
                "\n",
                "# Show the plot\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's zoom in on the very short descriptions:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the length of each product title\n",
                "df_text_train['description_length'] = df_text_train['description'].str.len()\n",
                "\n",
                "# Filter the DataFrame for description lengths shorter than 2196.5\n",
                "filtered_df = df_text_train[df_text_train['description_length'] < 100]\n",
                "\n",
                "# Plot the histogram\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.histplot(\n",
                "    data=filtered_df,\n",
                "    x='description_length',\n",
                "    bins=25,  # Number of bins for the histogram\n",
                "    kde=True,  # Add a kernel density estimate (smooth curve)\n",
                "    color='skyblue'\n",
                ")\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Distribution of Product Description Lengths (< 2196.5)', fontsize=16)\n",
                "plt.xlabel('Title Length (Number of Characters)', fontsize=14)\n",
                "plt.ylabel('Frequency', fontsize=14)\n",
                "plt.tight_layout()\n",
                "\n",
                "# Show the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let us take a look at very short descriptions, though they are not technically outliers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filter outliers above the upper whisker\n",
                "outliers_above = df_text_train[df_text_train['description_length'] < 30]\n",
                "\n",
                "# Display the descriptions of 5 outliers\n",
                "print(outliers_above['description'].head(5))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Some descriptions are essentially NaNs (e.g.) \"<br / >\", others seem to only add little information to the title (\"designation\"). More clear after cleaning and merger of title and description."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**6. Word Clouds of descriptions**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from data_viz import word_cloud\n",
                "word_cloud(df_text_train, 'prdtypecode', 'description')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**5. Word Clouds of designation**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "word_cloud(df_text_train, 'prdtypecode', 'designation')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "How much text did we save by cleaning?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the total number of characters in df_text_train['description'] and df_text_train['designation']\n",
                "total_description_chars = df_text_train['description'].str.len().sum()\n",
                "total_designation_chars = df_text_train['designation'].str.len().sum()\n",
                "\n",
                "# Calculate the total number of characters in df_merge['text_merged']\n",
                "total_text_merged_chars = df_merge['text_merged'].str.len().sum()\n",
                "\n",
                "# Print the results\n",
                "print(f\"Total characters in df_text_train['description']: {total_description_chars:,}\")\n",
                "print(f\"Total characters in df_text_train['designation']: {total_designation_chars:,}\")\n",
                "print(f\"Total characters in df_merge['text_merged']: {total_text_merged_chars:,}\")\n",
                "\n",
                "# Compare the totals\n",
                "print(\"\\nComparison:\")\n",
                "print(f\"Sum of df_text_train['description'] and df_text_train['designation']: {total_description_chars + total_designation_chars:,}\")\n",
                "print(f\"Total characters in df_merge['text_merged']: {total_text_merged_chars:,}\")\n",
                "print(f\"relative difference: {abs(total_description_chars + total_designation_chars - total_text_merged_chars) / (total_description_chars + total_designation_chars) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Calculate the length of strings in df_merge['text_merged']\n",
                "text_lengths = df_merge['text_merged'].str.len()\n",
                "\n",
                "# Create a boxplot\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(x=text_lengths, color='skyblue')\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Boxplot of String Lengths in df_merge[\"text_merged\"]', fontsize=14)\n",
                "plt.xlabel('Length of Strings', fontsize=12)\n",
                "\n",
                "# Show the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Calculate the length of strings in df_merge['text_merged']\n",
                "text_lengths = df_merge['description_cleaned'].str.len()\n",
                "\n",
                "# Create a boxplot\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(x=text_lengths, color='skyblue')\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Boxplot of String Lengths in df_merge[\"description_cleaned\"]', fontsize=14)\n",
                "plt.xlabel('Length of Strings', fontsize=12)\n",
                "\n",
                "# Show the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the IQR (Interquartile Range)\n",
                "Q1 = text_lengths.quantile(0.25)  # First quartile (25th percentile)\n",
                "Q3 = text_lengths.quantile(0.75)  # Third quartile (75th percentile)\n",
                "IQR = Q3 - Q1  # Interquartile range\n",
                "\n",
                "# Calculate the upper whisker threshold\n",
                "upper_whisker = Q3 + 1.5 * IQR\n",
                "\n",
                "# Count the number of outliers above the upper whisker\n",
                "outliers_above = df_text_train[text_lengths > upper_whisker]\n",
                "outlier_count = len(outliers_above)\n",
                "\n",
                "print(f\"The threshold for outliers is {upper_whisker} words in the description.\")\n",
                "print(f\"Number of outliers above the upper whisker: {outlier_count}\")\n",
                "print(f\"Percentage of outliers: {outlier_count / len(df_text_train) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Group by 'parent_category_en' and count the number of outliers\n",
                "outliers_by_category = outliers_above.groupby('parent_category_en').size()\n",
                "\n",
                "# Plot the results as a bar plot\n",
                "plt.figure(figsize=(10, 6))\n",
                "outliers_by_category.sort_values(ascending=False).plot(kind='bar', color='skyblue')\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Count of Outliers (Above Upper Whisker) by Parent Category', fontsize=14)\n",
                "plt.xlabel('Parent Category', fontsize=12)\n",
                "plt.ylabel('Count of Outliers', fontsize=12)\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.tight_layout()\n",
                "\n",
                "# Show the plot\n",
                "plt.show()\n",
                "\n",
                "# Print additional information\n",
                "print(f\"The threshold for outliers is {upper_whisker} characters in the description.\")\n",
                "print(f\"Number of outliers above the upper whisker: {len(outliers_above)}\")\n",
                "print(f\"Percentage of outliers: {len(outliers_above) / len(df_text_train) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "long_titles = df_text_train[df_text_train['designation'].str.len()>=240]\n",
                "pd.set_option('display.max_colwidth', None) \n",
                "# Peter 31mar2025: I would set this option in the setup section of the notebook after all imports\n",
                "print(long_titles['designation'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Count the number of duplicate entries in df_merge['text_merged']\n",
                "num_duplicates = df_merge['text_merged'].duplicated().sum()\n",
                "\n",
                "# Print the result\n",
                "print(f\"Number of duplicate entries in df_merge['text_merged']: {num_duplicates}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop duplicates based on 'designation_cleaned' and 'description_cleaned', keeping only the first occurrence\n",
                "unique_df = df_merge.drop_duplicates(subset=['designation_cleaned', 'description_cleaned'])\n",
                "\n",
                "# Calculate the total number of characters for the unique entries\n",
                "total_designation_cleaned_chars = unique_df['designation_cleaned'].str.len().sum()\n",
                "total_description_cleaned_chars = unique_df['description_cleaned'].str.len().sum()\n",
                "\n",
                "# Print the results\n",
                "print(f\"Total characters in unique df_merge['designation_cleaned'] + df_merge['description_cleaned']: {total_designation_cleaned_chars + total_description_cleaned_chars:,}\")\n",
                "print(f\"relative difference of clean and unique entries to original text length: {abs(total_description_chars + total_designation_chars - (total_designation_cleaned_chars + total_description_cleaned_chars)) / (total_description_chars + total_designation_chars) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If we can only translate the unique entries of the cleaned descriptions and titles ('designation'), before they are merged, we can save around 9% of characters maximum.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "long_descriptions = df_merge[df_merge['description_cleaned'].str.len()>=2200]\n",
                "pd.set_option('display.max_colwidth', None) \n",
                "# Peter 31mar2025: I would set this option in the setup section of the notebook after all imports\n",
                "display(long_descriptions['description_cleaned'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "I think to clean the description also did not work\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_11 = df_merge.iloc[[11]][['designation', 'description','designation_cleaned', 'description_cleaned', 'text_merged']]\n",
                "\n",
                "for index, row in df_11.iterrows():\n",
                "    print(f\"Row:\\n\\t{index}\")\n",
                "    print(f\"Designation:\\n\\t'{row['designation']}'\")\n",
                "    print(f\"Description:\\n\\t'{row['description']}'\")\n",
                "    print(f\"Cleaned Designation:\\n\\t'{row['designation_cleaned']}'\")\n",
                "    print(f\"Cleaned Description:\\n\\t'{row['description_cleaned']}'\")\n",
                "    print(f\"Merged Text:\\n\\t'{row['text_merged']}'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "How much text did we save by cleaning?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the total number of characters in df_text_train['description'] and df_text_train['designation']\n",
                "total_description_chars = df_text_train['description'].str.len().sum()\n",
                "total_designation_chars = df_text_train['designation'].str.len().sum()\n",
                "\n",
                "# Calculate the total number of characters in df_merge['text_merged']\n",
                "total_text_merged_chars = df_merge['text_merged'].str.len().sum()\n",
                "\n",
                "# Print the results\n",
                "print(f\"Total characters in df_text_train['description']: {total_description_chars:,}\")\n",
                "print(f\"Total characters in df_text_train['designation']: {total_designation_chars:,}\")\n",
                "print(f\"Total characters in df_merge['text_merged']: {total_text_merged_chars:,}\")\n",
                "\n",
                "# Compare the totals\n",
                "print(\"\\nComparison:\")\n",
                "print(f\"Sum of df_text_train['description'] and df_text_train['designation']: {total_description_chars + total_designation_chars:,}\")\n",
                "print(f\"Total characters in df_merge['text_merged']: {total_text_merged_chars:,}\")\n",
                "print(f\"relative difference: {abs(total_description_chars + total_designation_chars - total_text_merged_chars) / (total_description_chars + total_designation_chars) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Calculate the length of strings in df_merge['text_merged']\n",
                "text_lengths = df_merge['text_merged'].str.len()\n",
                "\n",
                "# Create a boxplot\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(x=text_lengths, color='skyblue')\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Boxplot of String Lengths in df_merge[\"text_merged\"]', fontsize=14)\n",
                "plt.xlabel('Length of Strings', fontsize=12)\n",
                "\n",
                "# Show the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Calculate the length of strings in df_merge['text_merged']\n",
                "text_lengths = df_merge['description_cleaned'].str.len()\n",
                "\n",
                "# Create a boxplot\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(x=text_lengths, color='skyblue')\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Boxplot of String Lengths in df_merge[\"description_cleaned\"]', fontsize=14)\n",
                "plt.xlabel('Length of Strings', fontsize=12)\n",
                "\n",
                "# Show the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the IQR (Interquartile Range)\n",
                "Q1 = text_lengths.quantile(0.25)  # First quartile (25th percentile)\n",
                "Q3 = text_lengths.quantile(0.75)  # Third quartile (75th percentile)\n",
                "IQR = Q3 - Q1  # Interquartile range\n",
                "\n",
                "# Calculate the upper whisker threshold\n",
                "upper_whisker = Q3 + 1.5 * IQR\n",
                "\n",
                "# Count the number of outliers above the upper whisker\n",
                "outliers_above = df_text_train[text_lengths > upper_whisker]\n",
                "outlier_count = len(outliers_above)\n",
                "\n",
                "print(f\"The threshold for outliers is {upper_whisker} words in the description.\")\n",
                "print(f\"Number of outliers above the upper whisker: {outlier_count}\")\n",
                "print(f\"Percentage of outliers: {outlier_count / len(df_text_train) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Group by 'parent_category_en' and count the number of outliers\n",
                "outliers_by_category = outliers_above.groupby('parent_category_en').size()\n",
                "\n",
                "# Plot the results as a bar plot\n",
                "plt.figure(figsize=(10, 6))\n",
                "outliers_by_category.sort_values(ascending=False).plot(kind='bar', color='skyblue')\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Count of Outliers (Above Upper Whisker) by Parent Category', fontsize=14)\n",
                "plt.xlabel('Parent Category', fontsize=12)\n",
                "plt.ylabel('Count of Outliers', fontsize=12)\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.tight_layout()\n",
                "\n",
                "# Show the plot\n",
                "plt.show()\n",
                "\n",
                "# Print additional information\n",
                "print(f\"The threshold for outliers is {upper_whisker} characters in the description.\")\n",
                "print(f\"Number of outliers above the upper whisker: {len(outliers_above)}\")\n",
                "print(f\"Percentage of outliers: {len(outliers_above) / len(df_text_train) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "long_titles = df_text_train[df_text_train['designation'].str.len()>=240]\n",
                "pd.set_option('display.max_colwidth', None) \n",
                "# Peter 31mar2025: I would set this option in the setup section of the notebook after all imports\n",
                "print(long_titles['designation'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Count the number of duplicate entries in df_merge['text_merged']\n",
                "num_duplicates = df_merge['text_merged'].duplicated().sum()\n",
                "\n",
                "# Print the result\n",
                "print(f\"Number of duplicate entries in df_merge['text_merged']: {num_duplicates}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop duplicates based on 'designation_cleaned' and 'description_cleaned', keeping only the first occurrence\n",
                "unique_df = df_merge.drop_duplicates(subset=['designation_cleaned', 'description_cleaned'])\n",
                "\n",
                "# Calculate the total number of characters for the unique entries\n",
                "total_designation_cleaned_chars = unique_df['designation_cleaned'].str.len().sum()\n",
                "total_description_cleaned_chars = unique_df['description_cleaned'].str.len().sum()\n",
                "\n",
                "# Print the results\n",
                "print(f\"Total characters in unique df_merge['designation_cleaned'] + df_merge['description_cleaned']: {total_designation_cleaned_chars + total_description_cleaned_chars:,}\")\n",
                "print(f\"relative difference of clean and unique entries to original text length: {abs(total_description_chars + total_designation_chars - (total_designation_cleaned_chars + total_description_cleaned_chars)) / (total_description_chars + total_designation_chars) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If we can only translate the unique entries of the cleaned descriptions and titles ('designation'), before they are merged, we can save around 9% of characters maximum.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "long_descriptions = df_merge[df_merge['description_cleaned'].str.len()>=2200]\n",
                "pd.set_option('display.max_colwidth', None) \n",
                "# Peter 31mar2025: I would set this option in the setup section of the notebook after all imports\n",
                "display(long_descriptions['description_cleaned'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "I think to clean the description also did not work\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_11 = df_merge.iloc[[11]][['designation', 'description','designation_cleaned', 'description_cleaned', 'text_merged']]\n",
                "\n",
                "for index, row in df_11.iterrows():\n",
                "    print(f\"Row:\\n\\t{index}\")\n",
                "    print(f\"Designation:\\n\\t'{row['designation']}'\")\n",
                "    print(f\"Description:\\n\\t'{row['description']}'\")\n",
                "    print(f\"Cleaned Designation:\\n\\t'{row['designation_cleaned']}'\")\n",
                "    print(f\"Cleaned Description:\\n\\t'{row['description_cleaned']}'\")\n",
                "    print(f\"Merged Text:\\n\\t'{row['text_merged']}'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "How much text did we save by cleaning?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the total number of characters in df_text_train['description'] and df_text_train['designation']\n",
                "total_description_chars = df_text_train['description'].str.len().sum()\n",
                "total_designation_chars = df_text_train['designation'].str.len().sum()\n",
                "\n",
                "# Calculate the total number of characters in df_merge['text_merged']\n",
                "total_text_merged_chars = df_merge['text_merged'].str.len().sum()\n",
                "\n",
                "# Print the results\n",
                "print(f\"Total characters in df_text_train['description']: {total_description_chars:,}\")\n",
                "print(f\"Total characters in df_text_train['designation']: {total_designation_chars:,}\")\n",
                "print(f\"Total characters in df_merge['text_merged']: {total_text_merged_chars:,}\")\n",
                "\n",
                "# Compare the totals\n",
                "print(\"\\nComparison:\")\n",
                "print(f\"Sum of df_text_train['description'] and df_text_train['designation']: {total_description_chars + total_designation_chars:,}\")\n",
                "print(f\"Total characters in df_merge['text_merged']: {total_text_merged_chars:,}\")\n",
                "print(f\"relative difference: {abs(total_description_chars + total_designation_chars - total_text_merged_chars) / (total_description_chars + total_designation_chars) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Calculate the length of strings in df_merge['text_merged']\n",
                "text_lengths = df_merge['text_merged'].str.len()\n",
                "\n",
                "# Create a boxplot\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(x=text_lengths, color='skyblue')\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Boxplot of String Lengths in df_merge[\"text_merged\"]', fontsize=14)\n",
                "plt.xlabel('Length of Strings', fontsize=12)\n",
                "\n",
                "# Show the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Calculate the length of strings in df_merge['text_merged']\n",
                "text_lengths = df_merge['description_cleaned'].str.len()\n",
                "\n",
                "# Create a boxplot\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(x=text_lengths, color='skyblue')\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Boxplot of String Lengths in df_merge[\"description_cleaned\"]', fontsize=14)\n",
                "plt.xlabel('Length of Strings', fontsize=12)\n",
                "\n",
                "# Show the plot\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate the IQR (Interquartile Range)\n",
                "Q1 = text_lengths.quantile(0.25)  # First quartile (25th percentile)\n",
                "Q3 = text_lengths.quantile(0.75)  # Third quartile (75th percentile)\n",
                "IQR = Q3 - Q1  # Interquartile range\n",
                "\n",
                "# Calculate the upper whisker threshold\n",
                "upper_whisker = Q3 + 1.5 * IQR\n",
                "\n",
                "# Count the number of outliers above the upper whisker\n",
                "outliers_above = df_text_train[text_lengths > upper_whisker]\n",
                "outlier_count = len(outliers_above)\n",
                "\n",
                "print(f\"The threshold for outliers is {upper_whisker} words in the description.\")\n",
                "print(f\"Number of outliers above the upper whisker: {outlier_count}\")\n",
                "print(f\"Percentage of outliers: {outlier_count / len(df_text_train) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Group by 'parent_category_en' and count the number of outliers\n",
                "outliers_by_category = outliers_above.groupby('parent_category_en').size()\n",
                "\n",
                "# Plot the results as a bar plot\n",
                "plt.figure(figsize=(10, 6))\n",
                "outliers_by_category.sort_values(ascending=False).plot(kind='bar', color='skyblue')\n",
                "\n",
                "# Add labels and title\n",
                "plt.title('Count of Outliers (Above Upper Whisker) by Parent Category', fontsize=14)\n",
                "plt.xlabel('Parent Category', fontsize=12)\n",
                "plt.ylabel('Count of Outliers', fontsize=12)\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.tight_layout()\n",
                "\n",
                "# Show the plot\n",
                "plt.show()\n",
                "\n",
                "# Print additional information\n",
                "print(f\"The threshold for outliers is {upper_whisker} characters in the description.\")\n",
                "print(f\"Number of outliers above the upper whisker: {len(outliers_above)}\")\n",
                "print(f\"Percentage of outliers: {len(outliers_above) / len(df_text_train) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "long_titles = df_text_train[df_text_train['designation'].str.len()>=240]\n",
                "pd.set_option('display.max_colwidth', None) \n",
                "# Peter 31mar2025: I would set this option in the setup section of the notebook after all imports\n",
                "print(long_titles['designation'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Count the number of duplicate entries in df_merge['text_merged']\n",
                "num_duplicates = df_merge['text_merged'].duplicated().sum()\n",
                "\n",
                "# Print the result\n",
                "print(f\"Number of duplicate entries in df_merge['text_merged']: {num_duplicates}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop duplicates based on 'designation_cleaned' and 'description_cleaned', keeping only the first occurrence\n",
                "unique_df = df_merge.drop_duplicates(subset=['designation_cleaned', 'description_cleaned'])\n",
                "\n",
                "# Calculate the total number of characters for the unique entries\n",
                "total_designation_cleaned_chars = unique_df['designation_cleaned'].str.len().sum()\n",
                "total_description_cleaned_chars = unique_df['description_cleaned'].str.len().sum()\n",
                "\n",
                "# Print the results\n",
                "print(f\"Total characters in unique df_merge['designation_cleaned'] + df_merge['description_cleaned']: {total_designation_cleaned_chars + total_description_cleaned_chars:,}\")\n",
                "print(f\"relative difference of clean and unique entries to original text length: {abs(total_description_chars + total_designation_chars - (total_designation_cleaned_chars + total_description_cleaned_chars)) / (total_description_chars + total_designation_chars) * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If we can only translate the unique entries of the cleaned descriptions and titles ('designation'), before they are merged, we can save around 9% of characters maximum.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "long_descriptions = df_merge[df_merge['description_cleaned'].str.len()>=2200]\n",
                "pd.set_option('display.max_colwidth', None) \n",
                "# Peter 31mar2025: I would set this option in the setup section of the notebook after all imports\n",
                "display(long_descriptions['description_cleaned'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "I think to clean the description also did not work\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_11 = df_merge.iloc[[11]][['designation', 'description','designation_cleaned', 'description_cleaned', 'text_merged']]\n",
                "\n",
                "for index, row in df_11.iterrows():\n",
                "    print(f\"Row:\\n\\t{index}\")\n",
                "    print(f\"Designation:\\n\\t'{row['designation']}'\")\n",
                "    print(f\"Description:\\n\\t'{row['description']}'\")\n",
                "    print(f\"Cleaned Designation:\\n\\t'{row['designation_cleaned']}'\")\n",
                "    print(f\"Cleaned Description:\\n\\t'{row['description_cleaned']}'\")\n",
                "    print(f\"Merged Text:\\n\\t'{row['text_merged']}'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prediction // Images: Find duplicates with perceptual hashing\n",
                "Create DataFrame with test products' designation and description"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_text_test = X_test.copy()\n",
                "df_text_test.set_index('productid', inplace=True)\n",
                "# df_text_test.to_parquet(\"df_text_test.parquet\")\n",
                "df_text_test.head()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
