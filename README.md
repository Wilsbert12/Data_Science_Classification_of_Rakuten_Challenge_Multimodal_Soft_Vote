# Rakuten Multimodal Product Classification

An AI-powered product classification system that combines text analysis and computer vision to automatically categorize e-commerce products, achieving state-of-the-art performance on the Rakuten France dataset.

## 🏆 Key Achievement

**Multimodal Ensemble F1-Score: 0.8727** - Exceeds official benchmark by **7.6%** (+6.14 points)
- **[🚀 Live Demo](https://classification-rakuten-challenge-multimodal-soft-vote.streamlit.app/)** - Interactive prediction interface
- **27 product categories** classified using text + image data from 99K+ product listings

## Project Overview

**Academic Context:** Capstone project for Data Science program demonstrating end-to-end machine learning pipeline development.

**Challenge:** [Rakuten Data Challenge](https://challengedata.ens.fr/challenges/35) - Automatically categorize products into correct type codes using both product descriptions and images.

- **Dataset:** 99K product listings (84,916 training, 13,812 test)
- **Modalities:** French/German text + product images
- **Metric:** Weighted F1-Score
- **Official Benchmarks:** Text CNN (0.8113), Image ResNet50 (0.5534)

**Solution:** Multimodal ensemble combining SVM, CamemBERT, and VGG16 models with optimized soft voting weights.

## Business Impact

### The Challenge
E-commerce platforms like Rakuten (1.3B+ users) face massive-scale product categorization challenges with diverse merchant data, multilingual content, and inconsistent labeling across international marketplaces.

### Impact Areas
- **🎯 Enhanced Customer Experience:** Faster product discovery, improved search, personalized recommendations
- **⚙️ Operational Excellence:** Automated categorization, faster onboarding, scalable operations
- **📈 Financial Performance:** Revenue growth through better discoverability, cost reduction via automation, optimized inventory management

### Strategic Value
Automated classification solution that substantially reduces manual overhead while improving accuracy for 27 distinct product categories with real-world data complexity (35% missing descriptions, multilingual content).

## Technical Approach & Architecture

### System Architecture
```mermaid
flowchart TD
    A["Raw Text (Product ID: 303967094)"] --> B["Designation:<br/>'Klarstein Uhrenbox für 2 Uhren'"]
    A --> C["Description:<br/>'&lt;br /&gt; Elegante Uhrenbox aus Holz<br/>für die Aufbewahrung von 2 Uhren...'<br/>(with HTML artifacts)"]
    
    B --> D[Combined Raw Text<br/>designation + description]
    C --> D
    
    D -->|"Language Detection"| E[German detected]
    E -->|"DeepL Translation"| F[Translated to French]
    F -->|"HTML Cleaning<br/>& Text Merging"| G["Merged Clean Text:<br/>'Présentoir de montres élégant en bois<br/>pour le rangement de 2 montres'<br/>(translated to French)"]
    
    G -->|"Minimal Processing<br/>for Context Preservation"| H["BERT-Ready Text:<br/>'Présentoir de montres élégant en bois<br/>pour le rangement de 2 montres'<br/>(minimal processing)"]
    
    H -->|"Accent Normalization<br/>+ Stop Words Removal<br/>+ Lowercasing"| I["Classical ML Text:<br/>'presentoir montres elegant bois<br/>rangement montres'<br/>(accent normalized + stop words removed)"]
    
    H --> J[CamemBERT Model]
    I --> K[SVM/Classical ML Models]
    
    subgraph TextFlow[" "]
        G
        H
        I
    end
    
    subgraph Models[" "]
        J
        K
    end
    
    style A fill:#ffebee
    style G fill:#e3f2fd
    style H fill:#e8f5e8
    style I fill:#fff3e0
    style J fill:#f3e5f5
    style K fill:#f3e5f5
```

### Ensemble Method: Soft Voting Classifier

**🏆 Multimodal Ensemble** - F1 Score: **0.8727** (exceeds benchmark by 7.6%)
- Optimized weights: SVM (40%), BERT (40%), VGG16 (20%)
- Clean validation on 3,191 samples with rigorous methodology

**Individual Models:**
- **SVM (Classical ML)** - F1: 0.763 | TF-IDF vectorized text with French preprocessing
- **CamemBERT (Transformer)** - F1: 0.863 | French language model with native tokenization  
- **VGG16 (Computer Vision)** - F1: 0.518 | Transfer learning for image classification

## Results & Performance

### Performance vs. Official Benchmarks
| Model | F1-Score | Modality | Benchmark | Performance | Status |
|-------|----------|----------|-----------|-------------|---------|
| **🏆 Ensemble** | **0.8727** | **Multimodal** | **0.8113** | **+7.6% ✅** | **EXCEEDS** |
| CamemBERT | 0.863 | Text | 0.8113 | +6% ✅ | Potential leakage |
| SVM | 0.763 | Text | 0.8113 | -6% | Clean evaluation |
| VGG16 | 0.518 | Image | 0.5534 | -6% | Clean evaluation |

### Key Achievements
- ✅ **7.6% improvement** over official text benchmark
- ✅ **10.97 point gain** over best individual clean model
- ✅ **Production-ready** ensemble with validated performance
- ✅ **Multimodal value proven** through rigorous validation

### Hypothesis Validation Results
| Hypothesis | Status | Key Finding |
|------------|--------|-------------|
| **H1: Inter-parent classification easier** | ✅ SUPPORTED | Hierarchical patterns confirmed |
| **H2: Intra-parent classification harder** | ✅ SUPPORTED | Logical complement of H1 |
| **H3: Image features help** | ❌ REJECTED | Text dominance established |
| **H4: Single-subcategory easier** | 🔄 SUGGESTIVE | Framework established, limited data |
| **H5: Complexity affects performance** | 🔄 SUGGESTIVE | Moderate correlation (r=-0.454, p=0.306) |
| **H6: Large categories perform better** | ❌ REJECTED | Performance driven by intrinsic characteristics |
| **H7: Visual characteristics vs quantity** | 🔬 FRAMEWORK READY | VGG16-specific analysis framework established |

## Repository Structure
```
├── data/                          # Datasets and preprocessing artifacts
│   ├── raw/                      # Original datasets (X_train.csv, y_train.csv, images/)
│   ├── processed/                # Enhanced metadata and PyTorch-ready folders
│   ├── language_analysis/        # Translation pipeline and results
│   └── vectorized_data/          # TF-IDF and count vectorizers
├── models/                       # Trained model artifacts
│   ├── svc_classifier.pkl        # SVM model
│   ├── vgg16_transfer_model.pth  # VGG16 CNN model
│   └── bert/                     # CamemBERT model files
├── results/                      # Performance metrics and evaluations
├── notebooks/                    # Sequential workflow (01-06 + reference/)
├── streamlit/                    # Interactive demo application
│   ├── Home.py                   # Main entry point
│   └── pages/                    # App pages (presentation to prediction)
├── api/                          # API-ready service layer
│   └── ensemble_service.py       # RakutenEnsembleClassifier
├── utils/                        # Utility functions (text, image, localization)
├── tests/                        # Unit tests and test data
└── requirements.txt              # Dependencies
```

## Installation & Usage

### Quick Start
```bash
# Clone and setup
git clone [repository-url]
cd rakuten-multimodal-classification
python3.11 -m venv rakuten-env
source rakuten-env/bin/activate  # Mac/Linux

# Install dependencies
pip install -r requirements.txt

# Run Streamlit app
streamlit run streamlit/Home.py
```

### Dataset Setup
- **Text data:** ✅ Included (`data/raw/X_train.csv`, `y_train.csv`)
- **Images:** 📥 Download separately from [Rakuten Challenge](https://challengedata.ens.fr/challenges/35) (~3-5GB)

### API-Ready Service
```python
# Direct model access
from api.ensemble_service import RakutenEnsembleClassifier
classifier = RakutenEnsembleClassifier()
```

## Technical Stack
- **ML/DL:** scikit-learn, transformers (CamemBERT), PyTorch, TensorFlow
- **Processing:** pandas, numpy, OpenCV, PIL, BeautifulSoup
- **NLP:** TF-IDF, CamemBERT tokenizer, langdetect, sentencepiece
- **Computer Vision:** VGG16 transfer learning, torchvision
- **Deployment:** Streamlit Cloud, lazy loading architecture
- **Translation:** DeepL API integration with caching

## Data Processing Pipeline

### Language & Translation
- **Language detection:** Automated French/non-French classification (langdetect)
- **Translation:** 23.4% non-French content pre-translated via DeepL API
- **Caching:** Results pre-computed to avoid API costs

### Text Processing
- **Dual pipelines:** Classical ML (accent normalization + French stop words) vs BERT (minimal preprocessing)
- **Feature engineering:** Title + description combination with model-specific optimization

### Image Processing
- **Complete pipeline:** Metadata extraction → bounding box detection → smart cropping → class organization
- **Results:** 100% processing success, 98.3% quality standards, 60-70% storage optimization
- **PyTorch-ready:** Stratified train/val splits across 27 categories

## Current Status & Next Steps

### ✅ Completed
- **Multimodal ensemble** exceeding benchmark performance
- **Production deployment** with lazy loading on Streamlit Cloud
- **Comprehensive evaluation** with hypothesis validation
- **API-ready architecture** for future scaling

### 🔄 Future Development
- **REST API Implementation:** FastAPI wrapper around existing service layer
- **MLOps Integration:** Experiment tracking and model versioning
- **Code Organization:** Streamlit utilities restructuring

## Development Architecture

### Local Development Best Practices
- **Python 3.11** virtual environment isolation
- **Git version control** with systematic experiment tracking
- **Reproducible splits** (`random_state=42` across all models)
- **Label encoding consistency** with runtime conversion system
- **Storage optimization** (60-70% reduction through intelligent processing)

### Deployment Strategy
```
Local Development → Git → GitHub → Streamlit Cloud
Direct model loading with lazy initialization for optimal performance
```

## Project Summary

Capstone project for Data Science program, demonstrating real-world multimodal classification in e-commerce.

**🎯 Achievement:** Production-ready ensemble system exceeding official benchmarks with comprehensive business impact analysis and live deployment.

---
*This project showcases end-to-end ML pipeline development from research through production deployment, with emphasis on practical business applications and technical excellence.*