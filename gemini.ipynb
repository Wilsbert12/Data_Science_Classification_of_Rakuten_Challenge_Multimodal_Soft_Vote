{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('language_analysis/df_langdetect.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'gemini_lang' in df.columns:\n",
    "    df = df\n",
    "else:\n",
    "    df['gemini_lang'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['de', nan, 'fr', 'en', 'ja', 'es', 'it', 'ko', 'gr', 'nl', 'pt',\n",
       "       'no', 'eu', 'sv', 'ru', 'ca', 'zh'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gemini_lang'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the texts or which langdetect did not get fr\n",
    "\n",
    "input_prompt_list = df[(df['merged_langdetect'] != 'fr') & pd.isna(df['gemini_lang'])]['merged_text'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16217"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_prompt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import ast\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variables\n",
    "api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"Error: GEMINI_API_KEY not found in environment variables or .env file.\")\n",
    "    exit()\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Select the Gemini model\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_call(prompt):\n",
    "    '''Gemini call to determine in language of text'''\n",
    "    try:\n",
    "        # Generate the response\n",
    "        response = model.generate_content(f'Without any formatting give me a dictionary with the items of the list as key and a two letter language code as value for the list: {prompt}')\n",
    "\n",
    "        # Print the generated text\n",
    "        return response.text # return response as dictionary\n",
    "    except Exception as e:        \n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"prompt\": prompt\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_limit = 25000 # gemini uses tokens with an output limited of 8,192 tokens as limit which corresponds to about 4 characters\n",
    "\n",
    "# first make sure that json file for output exist:\n",
    "file_path = 'language_analysis/gemini_result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16044 items to go\n",
      "15930 items to go\n",
      "15842 items to go\n",
      "15745 items to go\n",
      "15663 items to go\n",
      "15547 items to go\n",
      "15441 items to go\n",
      "15334 items to go\n",
      "15209 items to go\n",
      "15095 items to go\n",
      "15009 items to go\n",
      "14882 items to go\n",
      "14771 items to go\n",
      "14681 items to go\n",
      "14602 items to go\n",
      "14501 items to go\n",
      "14406 items to go\n",
      "14348 items to go\n",
      "14235 items to go\n",
      "14118 items to go\n",
      "14055 items to go\n",
      "13975 items to go\n",
      "13857 items to go\n",
      "13725 items to go\n",
      "13607 items to go\n",
      "13474 items to go\n",
      "13389 items to go\n",
      "13289 items to go\n",
      "13177 items to go\n",
      "13066 items to go\n",
      "12967 items to go\n",
      "12842 items to go\n",
      "12759 items to go\n",
      "12617 items to go\n",
      "12497 items to go\n",
      "12393 items to go\n",
      "12271 items to go\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "except (FileNotFoundError, json.JSONDecodeError):\n",
    "    data = {}  # Start with an empty list if file doesn't exist or is invalid\n",
    "prompts = []\n",
    "while input_prompt_list:\n",
    "    prompt = []\n",
    "    current_length = 0\n",
    "    while input_prompt_list:\n",
    "        next_element = input_prompt_list[0]\n",
    "        next_length = len(next_element)\n",
    "\n",
    "        if current_length + next_length > gemini_limit:\n",
    "            break\n",
    "\n",
    "        prompt.append(input_prompt_list.pop(0))\n",
    "        current_length += next_length\n",
    "    result = gemini_call(prompt)\n",
    "    if type(result) != dict:\n",
    "        try:\n",
    "            result = ast.literal_eval(result)\n",
    "        except:\n",
    "            prefix = \"```python\"\n",
    "            suffix = \"```\"\n",
    "            if result.startswith(prefix):\n",
    "                result = result[len(prefix):]\n",
    "                result = result[:-len(suffix)]\n",
    "                result = ast.literal_eval(result)\n",
    "            #cleanup:\n",
    "    if type(result) == dict:\n",
    "\n",
    "        data.update(result)  # Merge the new result into the existing data\n",
    "        with open(file_path, \"w\") as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "    else:\n",
    "        error_result = {\n",
    "            \"prompt\": prompt,\n",
    "            \"result\": result\n",
    "        }\n",
    "        with open('language_analysis/gemini_reponse_error.json', \"a\") as file:\n",
    "            json.dump(error_result, file, indent=4)\n",
    "    print(f'{len(input_prompt_list)} items to go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "df['gemini_lang'] = df['merged_text'].map(data)\n",
    "df.to_csv('language_analysis/df_langdetect.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
