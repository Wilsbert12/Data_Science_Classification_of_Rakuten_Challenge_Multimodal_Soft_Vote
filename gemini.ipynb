{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('language_analysis/df_langdetect.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'gemini_lang' in df.columns:\n",
    "    df = df\n",
    "else:\n",
    "    df['gemini_lang'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['de', nan, 'fr', 'en', 'ja', 'es', 'it', 'ko', 'gr', 'nl', 'pt',\n",
       "       'no', 'eu', 'sv', 'ru', 'ca', 'zh', 'la', 'vo', 'pl', 'is', 'tl',\n",
       "       'tr', 'da'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gemini_lang'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the texts or which langdetect did not get fr\n",
    "\n",
    "input_prompt_list = df[(df['merged_langdetect'] != 'fr') & pd.isna(df['gemini_lang'])]['merged_text'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8583"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_prompt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import ast\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variables\n",
    "api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"Error: GEMINI_API_KEY not found in environment variables or .env file.\")\n",
    "    exit()\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Select the Gemini model\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_call(prompt):\n",
    "    '''Gemini call to determine in language of text'''\n",
    "    try:\n",
    "        # Generate the response\n",
    "        response = model.generate_content(f'Without any formatting give me a dictionary with the items of the list as key and a two letter language code as value for the list: {prompt}')\n",
    "\n",
    "        # Print the generated text\n",
    "        return response.text # return response as dictionary\n",
    "    except Exception as e:        \n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"prompt\": prompt\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_limit = 25000 # gemini uses tokens with an output limited of 8,192 tokens as limit which corresponds to about 4 characters\n",
    "\n",
    "# first make sure that json file for output exist:\n",
    "file_path = 'language_analysis/gemini_result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse result: name 're' is not defined\n",
      "Failed to parse result: name 're' is not defined\n",
      "Failed to parse result: name 're' is not defined\n"
     ]
    }
   ],
   "source": [
    "def parse_result(result):\n",
    "    if not isinstance(result, dict):\n",
    "        try:\n",
    "            return ast.literal_eval(result)\n",
    "        except:\n",
    "            try:\n",
    "                code = re.search(r\"```(?:python)?\\s*(.*?)```\", result, re.DOTALL | re.IGNORECASE).group(1).strip()\n",
    "                return ast.literal_eval(code)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to parse result: {e}\")\n",
    "                return None\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "try:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "except (FileNotFoundError, json.JSONDecodeError):\n",
    "    data = {}  # Start with an empty list if file doesn't exist or is invalid\n",
    "prompts = []\n",
    "while input_prompt_list:\n",
    "    prompt = []\n",
    "    current_length = 0\n",
    "    while input_prompt_list:\n",
    "        next_element = input_prompt_list[0]\n",
    "        next_length = len(next_element)\n",
    "\n",
    "        if current_length + next_length > gemini_limit:\n",
    "            break\n",
    "\n",
    "        prompt.append(input_prompt_list.pop(0))\n",
    "        current_length += next_length\n",
    "    result = gemini_call(prompt)\n",
    "    try:\n",
    "        parsed = parse_result(result)\n",
    "        data.update(parsed)\n",
    "        with open(file_path, \"w\") as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "    except:\n",
    "        with open('language_analysis/gemini_reponse_error.json', \"w\") as file:\n",
    "            error_data = json.load(file)\n",
    "            error_data.update({\"prompt\": prompt, \"result\": result})\n",
    "            json.dump(error_data, file, indent=4)\n",
    "\n",
    "print(f'{len(input_prompt_list)} items to go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "df['gemini_lang'] = df['merged_text'].map(data)\n",
    "df.to_csv('language_analysis/df_langdetect.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
