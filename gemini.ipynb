{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('language_analysis/df_langdetect.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'gemini_lang' in df.columns:\n",
    "    df = df\n",
    "else:\n",
    "    df['gemini_lang'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['de', nan, 'fr', 'en', 'ja', 'es', 'tr', 'el', 'it', 'nl', 'pt',\n",
       "       'da', 'sv', 'ko', 'mul', 'ca', 'zh', 'la', 'vo', '??', 'pl', 'ru',\n",
       "       'tl', 'und', 'cs'], dtype=object)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gemini_lang'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the texts or which langdetect did not get fr\n",
    "\n",
    "input_prompt_list = df[(df['merged_langdetect'] != 'fr') & pd.isna(df['gemini_lang'])]['merged_text'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_prompt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Livre intégralement en italien. Le delocalizzazioni avvantagiano soltanto un'élite finanziaria. Ora se i tassi di cambio sono stabiliti nel rispetto della parità dei poteri d'acquisto le delocalizzazioni perdono ogni interesse. Il ruolo dei responsabili politici economici e monetari è messo in causa dato che essi sono tutti sotto l'influenza di coloro che dalle delocalizzazioni traggono profitto. L'autore dimostra che esistono soluzioni economiche : occorre solo il coraggio politico di applicarle.\",\n",
       " 'Lanceur complet pour Moteur de tondeuse Briggs & stratton Moteur Briggs & stratton - Lanceur complet compatible avec 12h809-1795-b1 124t05 122682 122h82 111607 12q507 12s882 123j09 12d802 123j02 12g882 12z802 12m887 125607 12g807 12s512 127712 128812 12g602 12j612 12s702 12e707 120612 125h82 127782 128m07 12s602 127802 129h07 12f889 120609 205412 12s605 128h02 12j882 12e787 12h612 129h02 12g612 12s612 204437 12e802 125602 120l02 12h672 120t02 125k02 12h887 12k602 12g702 12f887 121686 12l802 12j809 121687 128882 122602 110602 121h02 12k607 12s887 12k612 110682 121h82 110612 121k02 12k682 12f787 126m07 12l887 126t02 205457 205455 12k687 12l882 12q502 129887 12e782 12u802 12j887 12p802 12j902 127605 12l902 127609 12m902 12s707 12b802 128712 127702 12q802 122607 12f807 12d602 126l12 12t707 12c602 128802 124k02 120602 127707 12j805 12s787 122612 12f612 122672 12b602 12t702 122k05 122k07 124h82 12t782 128h07 205452 11a602 128m02 12g782 124h02 205417 12a602 12g802 11a682 12e602 11a687 11c602 12d607 120h07 12d672 12t787 120607 123k07 124t02 123k05 12f702 126t12 12f805 12j807 120h02 128m05 122t02 120k02 12d677 127607 12f802 12h707 120682 126k02 129787 111602 12f782 205432 12g787 126t07 128l05 127602 12h805 121605 128l02 121606 122m05 121607 122677 124l02 122l05 12q505 129782 12t882 12h809-1795-b1 124t05 122682 122h82 111607 12q507 111682 128805 122l02 124672 125k09 123602 129707 128807 12h802-2028-b1 099772 204415 126602 125672 129802 12j707 12e702 122k02 125682 127807 12c682 129807 111687 121602 099777 204412 12q512 124l07 12h702 12h809 204417 12a802 12g812 099776 12q572 12t807 124l05 128l07 205437 126606 12h802 126607 125k05 123607 122m07 125k07 126t05 127882 128602 127809 12r507 12r512 12w802 12m802 124t12 122k82 12r602 12k702 127h02 12s802 12r605 124602 121609 12s502 126m05 127887 12f882 12v882 123k12 12v809 12m882 129812 129882 121612 12h812 12f809 12v807 12e807 128605 12t887 12s807 204432 127787 12y802 12c882 128607 127h07 12h712 128612 128702 12z602 129602 126l02 12c802 129612 12t802 129702 12c702 123h07 128809 128t07 12j602 12c807 12s505 123h02 128887 122h07 12x812 126m02 121672 12m807 121682 12x882 125h02 12w807 12h602 121k12 122h02 123k02 12s507 125h07 12f707 12x802 12s882 123j09 12d802 123j02 12g882 12z802 12m887 125607 12g807 12s512 127712 128812 12g602 12j612 12s702 12e707 120612 125h82 127782 128m07 12s602 127802 129h07 111682 128805 122l02 124672 125k09 123602 129707 128807 12h802-2028-b1 099772 204415 126602 125672 129802 12j707 12e702 122k02 125682 127807 12c682 129807 111687 121602 099777 204412 12q512 124l07 12h702 12h809 204417 12a802 12g812 099776 12q572 12t807 124l05 128l07 205437 126606 12h802 126607 125k05 123607 122m07 125k07 126t05 127882 128602 127809 12q577 12q677 12g887 12r502 124682 122t05 128t05 12j702 123k09 124t07 123672 12h807 12j802 12r505 12f812 122k09 122k12 12h882 12v802 12r507 12r512 12w802 12m802 124t12 122k82 12r602 12k702 127h02 12s802 12r605 124602 121609 12s502 126m05 127887 12f882 12v882 123k12 12v809 12m882 129812 129882 121612 12h812 12f809 12v807 12e807 128605 12t887 12s807 204432 127787 12y802 12c882 128607 127h07 12h712 128612 128702 12z602 129602 126l02 12c802 129612 12t802 129702 12c702 123h07 128809 128t07 12j602 12c807 12s505 123h02 128887 122h07 12x812 126m02 121672 12m807 121682 12x882 125h02 12w807 12h602 121k12 122h02 123k02 12s507 125h07 12f707 12x802 12f889 120609 205412 12s605 128h02 12j882 12e787 12h612 129h02 12g612 12s612 204437 12e802 125602 120l02 12h672 120t02 125k02 12h887 12k602 12g702 12f887 121686 12l802 12j809 121687 128882 122602 110602 121h02 12k607 12s887 12k612 110682 121h82 110612 121k02 12k682 12f787 126m07 12l887 126t02 205457 205455 12k687 12l882 12q502 129887 12e782 12u802 12j887 12p802 12j902 127605 12l902 127609 12m902 12s707 12b802 128712 127702 12q802 122607 12f807 12d602 126l12 12t707 12c602 128802 124k02 120602 127707 12j805 12s787 122612 12f612 122672 12b602 12t702 122k05 122k07 124h82 12t782 128h07 205452 11a602 128m02 12g782 124h02 205417 12a602 12g802 11a682 12e602 11a687 12d672 12t787 120607 123k07 124t02 123k05 12f702 126t12 12f805 12j807 120h02 128m05 122t02 120k02 12d677 127607 12f802 12h707 120682 126k02 129787 111602 12f782 205432 12g787 126t07 128l05 127602 12h805 121605 128l02 121606 122m05 121607 122677 124l02 122l05 12q505 129782 12t882 12q577 12q677 12g887 12r502 124682 122t05 128t05 12j702 123k09 124t07 123672 12h807 12j802 12r505 12f812 122k09 122k12 12h882 12v802 11c602 12d607 120h07']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prompt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[502, 4460, 1120]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in input_prompt_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os # used for importing the API KEY\n",
    "from pathlib import Path\n",
    "import re\n",
    "import ast\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the environment variables\n",
    "api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"Error: GEMINI_API_KEY not found in environment variables or .env file.\")\n",
    "    exit()\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Select the Gemini model\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_call(prompt):\n",
    "    '''Gemini call to determine in language of text'''\n",
    "    try:\n",
    "        # Generate the response\n",
    "        response = model.generate_content(f'Without any formatting give me a dictionary with the items of the list as key and a two letter language code as value for the list: {prompt}')\n",
    "\n",
    "        # Print the generated text\n",
    "        return response.text # return response as dictionary\n",
    "    except Exception as e:        \n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"prompt\": prompt\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_limit = 25000 # gemini uses tokens with an output limited of 8,192 tokens as limit which corresponds to about 4 characters\n",
    "#If the gemini_limit is high we will see more failures but need less calls one option is to keep the limit high first e.g. 25000 and than set it lower to capture the elements that first fail e.g. 18000\n",
    "#Alternativily you can also just run the script multiple times since the slices will shift every time so it might just run with one of the reorderings\n",
    "\n",
    "\n",
    "# first make sure that json file for output exist:\n",
    "file_path = 'language_analysis/gemini_result.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 items to go\n"
     ]
    }
   ],
   "source": [
    "def parse_result(result):\n",
    "    if not isinstance(result, dict):\n",
    "        try:\n",
    "            return ast.literal_eval(result)\n",
    "        except:\n",
    "            try:\n",
    "                code = re.search(r\"```(?:python)?\\s*(.*?)```\", result, re.DOTALL | re.IGNORECASE).group(1).strip()\n",
    "                return ast.literal_eval(code)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to parse result: {e}\")\n",
    "                return None\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "try:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "except (FileNotFoundError, json.JSONDecodeError):\n",
    "    data = {}  # Start with an empty list if file doesn't exist or is invalid\n",
    "prompts = []\n",
    "while input_prompt_list:\n",
    "    prompt = []\n",
    "    current_length = 0\n",
    "    while input_prompt_list:\n",
    "        next_element = input_prompt_list[0]\n",
    "        next_length = len(next_element)\n",
    "\n",
    "        if current_length + next_length > gemini_limit:\n",
    "            break\n",
    "\n",
    "        prompt.append(input_prompt_list.pop(0))\n",
    "        current_length += next_length\n",
    "    result = gemini_call(prompt)\n",
    "    try:\n",
    "        parsed = parse_result(result)\n",
    "        data.update(parsed)\n",
    "        with open(file_path, \"w\") as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "    except:\n",
    "        error_path = Path(\"language_analysis/gemini_reponse_error.json\")\n",
    "        try:\n",
    "            error_data = json.loads(error_path.read_text())\n",
    "        except (FileNotFoundError, json.JSONDecodeError):\n",
    "            error_data = {}\n",
    "\n",
    "        error_data.update({\"prompt\": prompt, \"result\": result})\n",
    "        error_path.write_text(json.dumps(error_data, indent=4))\n",
    "\n",
    "    print(f'{len(input_prompt_list)} items to go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "df['gemini_lang'] = df['merged_text'].map(data)\n",
    "df.to_csv('language_analysis/df_langdetect.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
